<script>
    this.fail = false;
    var self = this;
    try {
        /*
        var a = await fetch("/ping",{method:"POST"});
        if(a.status==404) {
            this.fail = true;
            self.props.fail();
        }
        */
    } catch(e) {
        this.fail = true;
        self.props.fail();
    }

    this.refresh_list = new Promise((resolve,reject)=>{
        Import({url:"/list",method:"GET"})
        .done((data)=>{
            //alert(data);
            var json = JSON.parse(data);
            resolve(json);
            
        })
        .send();
    });


    function genId(schema,size) {
        if(!schema) {
            schema = "";
        }
        var code = 'xxxxxxxxxxxxxxxx';
        if(size) {
            var sb = [];
            for(var x = 0; x < size;x++) {
                sb.push("x");
            }
            code = sb.join("");
        }
        return schema+(code).replace(/[x]/g, function(c) {
            var r = Math.random() * 16 | 0;
            if( c == 'x' ) {
                return r.toString(16);
            } else {
                return c;
            }
        });
    }
    this.genId = genId;

</script>
<style>
    body {
        margin:0px;
    }
</style>
<div style="display:flex;background-color:navy;color:white;padding:10px;">
    <div>🧊 NumberCooler Recorder Premium</div>
</div>
<div id="main" style="display:flex;padding:0px;border-left:solid 10px navy;border-right:solid 10px navy;">
    <div id="listPanel" style="flex:0.6;overflow:auto;">
        <div id="listPanelMock"></div>
        <table border="1" width="100%" cellpadding="0" cellspacing="0">
            <Component id="list"></Component>
        </table>
        <Component id="message"></Component>
        <div style="height:40px;"></div>
    </div>
    <div style="width:5px;background-color:navy;"></div>
    <div id="mainPanel" style="flex:1;padding:20px;overflow:auto;">
        
        <div id="lblSettings" style="cursor:pointer;">🔧 Settings</div>
        <div id="settingsPanel">
            <div style="padding-left:20px;">Output</div>
                <div style="padding-left:20px;">
                    <div style="padding-left:20px;">
                        <div>📺 Video</div>
                        <div style="padding-left:20px;">
                            <div>Resolution</div>
                            <div style="padding-left:20px;">
                                <div style="display:flex;">
                                    <div style="width:150px;border-right:solid 1px #000;padding-right:10px;">
                                        <div style="display:flex;">
                                            <div style="flex:1;">width</div><div><input id="screenWidth" type="text" value="320" style="width:50px;"/></div>
                                        </div>
                                        <div style="display:flex;">
                                            <div style="flex:1;">height</div><div><input id="screenHeight" type="text" value="240" style="width:50px;"/></div>
                                        </div>
                                    </div>
                                    <div style="font-weight:bold;font-size:10px;padding-left:10px;">
                                        <div>(4:3)</div>
                                        <div style="display:flex;padding-left:10px;">
                                            <div id="btnResQVGA" style="margin-right:10px;">QVGA</div>
                                            <div id="btnResVGA" style="margin-right:10px;">VGA</div>
                                            <div id="btnResSVGA" style="margin-right:10px;">SVGA</div>
                                            <div id="btnResXGA" style="margin-right:10px;">XGA</div>
                                        </div>
                                        <div>(16:9)</div>
                                        <div style="display:flex;padding-left:10px;">
                                            <div id="btnResFWVGA" style="margin-right:10px;">FWVGA</div>
                                            <div id="btnResHD720" style="margin-right:10px;">HD 720</div>
                                            <div id="btnResHD1080" style="margin-right:10px;">HD 1080</div>
                                        </div>
                                        <div>(custom)</div>
                                        <div style="display:flex;padding-left:10px;">
                                            <div id="btnResTwitter1" style="margin-right:10px;">Twitter Post</div>
                                            <div id="btnResFacebook1" style="margin-right:10px;">Facebook Post</div>
                                            <div id="btnResFacebook2" style="margin-right:10px;">Facebook Comment</div>
                                        </div>

                                    </div>
                                </div>
                            </div>
                        
                        </div>

                    </div>

                </div>
            
            
        </div>



        <div>🎬 Scene Stack (layer channel)</div>
        <ul>
            <li>stream channel admin : add channel, remove channel. channel : add keyframe, remove keyframe. keyframe : ? a keyframe may go inheriting tracks and channel.</li>

            <div style="padding:5px;display:flex;">
                <div style="display:flex;">
                    <div><input id="txtLayerChannelName" type="text"/></div><div><button  id="btnAddLayerChannel">add</button></div>
                </div>
                <div><button  id="btnRemoveLayerChannel">remove</button></div>
                <div><button  id="btnUpLayerChannel">up</button></div>
                <div><button  id="btnDownLayerChannel">down</button></div>
            </div>
            <div style="padding:5px;border:solid 1px #000;">
                <div><Component id="layerChannelList"></Component></div>
                
            </div>
            
        </ul>


        <div id="lblSettings" style="cursor:pointer;">🔧 Toolbar</div>
        <div id="settingsPanel">
            <div style="padding-left:20px;">Input</div>
            <div style="padding-left:20px;">
                <div style="padding-left:20px;">
                    
                    <div>
                        <div>🔊 Audio</div>
                        <div style="padding-left:20px;">
                            <div>
                                none
                                <button id="btnSetAudioNone">set</button>
                            </div>
                            <div>
                                microphone
                                <select id="mic_devices"></select>
                                <button id="btnAddMic">add</button>
                            </div>
                            <div>
                                audio file
                                <input id="fileAudio" type="file" multiple="true"/>
                                <button id="btnAddAudioFile">add</button>
                            </div>
                        </div>
                    </div>
                    <div>
                        <div>📺 Video</div>
                        <div style="padding-left:20px;">
                            <div>
                                none
                                <button id="btnSetVideoNone">set</button>
                            </div>
                            <div>
                                screen
                                <button id="btnAddScreen">add</button>
                            </div>
                            <div>
                                camera
                                <select id="video_devices"></select>
                                <button id="btnAddCamera">add</button>
                            </div>
                            <div>
                                image/video file
                                <input id="fileImage" type="file" multiple="true"/>
                                <button id="btnAddImageVideoFile">add</button>
                            </div>
                            <div>
                                text
                                <button id="btnAddText">add</button>
                            </div>

                        </div>
                    </div>
                    <div style="height:40px;"></div>
                </div>
            </div>
        </div>

        
        <div>🎬 Stage</div>
        <div style="display:flex;">
            <button id="btnRecord">start recording</button>
            <button id="btnPlay">play</button>
            <button id="btnClearStage">clear</button>
            <div style="flex:1;"></div>
            <button id="btnDownloadMovie">download record</button>
        </div>
        
        <div style="padding-left:20px;">
            <div id="lblTracks" style="display:none;">
                <div>🛵 Tracks</div>
                <div style="display:flex;flex-wrap: wrap;">
                    <Component id="tracksView"></Component>
                </div>
            </div>
            <script>
                /*
                    Camera Hit Tracks
                    Movie Hit Tracks
                    Canvas Hit Tracks
                */
            </script>
        </div>
        <div style="display:flex;padding-top:10px;padding-bottom:10px;">
            <div id="chkMic" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">🔴 Mic</div>
            <div id="chkScreen" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">🔴 Screen</div>
            <div id="chkCamera" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">🔴 Camera</div>
            <div id="chkCanvas" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">🔴 Canvas</div>
        </div>
        <div id="mockHolder"></div>
        <div id="recordHolder">
            <Component id="mic_holder"></Component>
            <Component id="mic_holder2"></Component>
            <Component id="camera_holder"></Component>
        </div>
        <div id="playholder" style="display:none;">
            <div>🔵 Last Record</div>
            <video id="playscreen"></video>
            <Component id="playaudio"></Component>
        </div>
        <div>
            <button id="btnSend">save</button>
        </div>
        <div style="height:40px;"></div>
        <div>🐞 Debug</div>
        <div id="debug" style="font-family:'Cascadia Mono';font-size:10px;border:solid 2px #000; padding:20px;"></div>
        
    </div>
</div>
<div style="display:flex;background-color:navy;color:white;padding:10px;">
    <div style="flex:1;"></div><div>📋 Version 1.0 📅 July 2020</div>
</div>

<script>
if(this.fail) {
    main.el.style.display = "none";
    message.$.elementSetPacketAsync(`Hello World!`);
}


btnResQVGA.el.addEventListener("click",()=>{
    screenWidth.el.value = "320";
    screenHeight.el.value = "240";
});
btnResVGA.el.addEventListener("click",()=>{
    screenWidth.el.value = "640";
    screenHeight.el.value = "480";
});
btnResSVGA.el.addEventListener("click",()=>{
    screenWidth.el.value = "800";
    screenHeight.el.value = "600";
});
btnResXGA.el.addEventListener("click",()=>{
    screenWidth.el.value = "1024";
    screenHeight.el.value = "768";
});
btnResFWVGA.el.addEventListener("click",()=>{
    screenWidth.el.value = "854";
    screenHeight.el.value = "480";
});
btnResHD720.el.addEventListener("click",()=>{
    screenWidth.el.value = "1280";
    screenHeight.el.value = "720";
});
btnResHD1080.el.addEventListener("click",()=>{
    screenWidth.el.value = "1920";
    screenHeight.el.value = "1080";
});
btnResTwitter1.el.addEventListener("click",()=>{
    screenWidth.el.value = "440";
    screenHeight.el.value = "220";
});
btnResFacebook1.el.addEventListener("click",()=>{
    screenWidth.el.value = "500";
    screenHeight.el.value = "282";
});
btnResFacebook2.el.addEventListener("click",()=>{
    screenWidth.el.value = "480";
    screenHeight.el.value = "120";
});


listPanel.el.style.height = (window.innerHeight-90) + "px";
mainPanel.el.style.height = (window.innerHeight-130) + "px";




var self = this;
this.app = {
    events : Class.create("WithEvents"),
    panel : {
        settings : {
            visible : true
        }
    },
    stream : null,
    tracks : [],
    recordType : "none",
    recordState : "stopped",
    video : {
        mode : "none",
        output : {
            init : false
        }
    },
    audio : {
        mode : "none",
        output : "default"
    },
    hasAudioTracks : function () { for(var x = 0; x < this.tracks.length;x++) if(this.tracks[x].type == "audio") return true; return false; },
    hasVideoTracks : function () { for(var x = 0; x < this.tracks.length;x++) if(this.tracks[x].type == "video") return true; return false; }
};


self.app.audio.layers = [];

var default_video_layers = [{ 
    name : "ms", track : -1, lastTrack : -1, grid : [1,1], pos : [0,0]
},{ 
    name : "pip", track : -1, lastTrack : -1, grid : [2,2], pos : [1,1]
}];

self.app.video.layers = default_video_layers;
self.app.video.layerSelected = null;
async function add_layer(layer) {
    if(!layer.init) {
        layer.init = true;
        layer.selected = false;
        var schema = await layerChannelList.$.elementPushPacketAsync(`
            <Component id="control">
                <div id="layer">${layer.name}</div>
            </Component>
        `);
        layer.schema = schema;

        schema.el.layer.addEventListener("mouseover",()=>{
            if(!layer.selected && self.app.video.layerSelected!=layer) {
                schema.el.layer.style.backgroundColor = "navy";
                schema.el.layer.style.color = "white";
            }
        });
        schema.el.layer.addEventListener("mouseleave",()=>{
            if(!layer.selected) {
                schema.el.layer.style.backgroundColor = "";
                schema.el.layer.style.color = "";
            }
        });
        schema.el.layer.addEventListener("click",()=>{
            var same = false;
            if(self.app.video.layerSelected == layer) {
                same = true;
            }

            if(self.app.video.layerSelected) {
                self.app.video.layerSelected.schema.$.layer.emit("deselect",[self.app.video.layerSelected]);
            }
            if(!layer.selected) {
                self.app.video.layerSelected = layer;
                schema.el.layer.style.backgroundColor = "red";
                schema.el.layer.style.color = "white";
                layer.selected = true;
            } else {
                
                self.app.video.layerSelected = null;
                schema.el.layer.style.backgroundColor = "navy";
                schema.el.layer.style.color = "white";
                layer.selected = false;
            }
        });
        schema.$.layer.on("dispose",()=>{
            schema.$.control.elementsClear();
        });
        schema.$.layer.on("deselect",(layer)=>{
            console.log("OK");
            layer.selected = false;
            schema.el.layer.style.backgroundColor = "";
            schema.el.layer.style.color = "";
        });
    }
}
function refresh_layerchannels() {
    for(var x = 0; x < self.app.video.layers.length;x++) {
        add_layer(self.app.video.layers[x]);
    }
}
refresh_layerchannels();

btnAddLayerChannel.el.addEventListener("click",()=>{
    var n = self.app.video.layers.length;
    console.log("add");
    self.app.video.layers.push({
        name:txtLayerChannelName.el.value,
        track : -1, lastTrack : -1, grid : [n,n], pos : [n-1,n-1]
    });
    refresh_layerchannels();
});

btnRemoveLayerChannel.el.addEventListener("click",()=>{
    if(self.app.video.layerSelected) {
        for(var x = 0; x < self.app.video.layers.length;x++) {
            if(self.app.video.layerSelected == self.app.video.layers) {
                self.app.video.layers.splice(x,0); // remove from db
                break;
            }
        }
        self.app.video.layerSelected.schema.$.layer.emit("dispose");
        self.app.video.layerSelected = null;
    }
    console.log("remove");
})


async function refresh_list(update) {
    var data = null;
    if(update) {
        data = await new Promise((resolve,reject)=>{
            Import({url:"/list",method:"GET"})
            .done((data)=>{
                //alert(data);
                var json = JSON.parse(data);
                resolve(json);
                
            })
            .send();
        });
    } else {
        data = await self.refresh_list;
    }
    if(data?.result) {
        schema.$.list.elementsClear();
        for(var x = 0; x < data.data.length;x++) {
            addAsset(data.data[x]);
        }
    }    
}
refresh_list();

btnClearStage.el.addEventListener("click",()=>{
    self.app.video.canvasFlag = false;
    self.app.video.output.init = false;
    camera_holder.$.elementsClear();
    tracksView.$.elementsClear();
    if(self.app.video.pixi) self.app.video.pixi.destroy();

    // stop video streams
    for(var x = 0; x < self.app.tracks.length;x++) {
        var track = self.app.tracks[x];
        if(track.type == "video" && ( track.data.type == "camera" || track.data.type == "clip" || track.data.type == "screen")) {
            track.data.stream.getTracks().forEach((track)=>{
                track.stop();
            })
        }
    }
    mic_holder.$.elementsClear();
    // stop audio streams
    for(var x = 0; x < self.app.audio.layers.length;x++) {
        var layer = self.app.audio.layers[x];
        layer.stream.getTracks().forEach((track)=>{
            track.stop();
        });
    }
    self.app.audio.layers.splice(0,self.app.audio.layers.length);

    self.app.tracks.splice(0,self.app.tracks.length);
    self.app.events.emit("updateTracks");
});

lblSettings.el.addEventListener("click",()=>{
    if(self.app.panel.settings.visible) {
        settingsPanel.el.style.display = "none";
        self.app.panel.settings.visible = false;
    } else {
        settingsPanel.el.style.display = "";
        self.app.panel.settings.visible = true;

    }
})


// https://rawgit.com/Miguelao/demos/master/mediarecorder.html
//https://webrtc.github.io/samples/src/content/capture/canvas-record/
//https://webrtc.github.io/samples/src/content/capture/canvas-record/
function log(str) {
    debug.$.elementPushPacketAsync(`<div>${str}</div>`);
}
//canvas



// devices

var stream = null;
self.app.stream = null;


let audioStream0 = null;


var stream0 = await navigator.mediaDevices.getUserMedia({video:true,audio:true});
stream0.getTracks().forEach(function(track) {
    track.stop();
});


navigator.mediaDevices.enumerateDevices()
  .then(gotDevices)
  .catch((error)=>{
    log('Error: '+ error.message);   
  });

async function gotDevices(deviceInfos) {
    //camera.el.srcObject = await navigator.mediaDevices.getUserMedia({video: true});
    //getStream();
    
    //camera.el.srcObject = await navigator.mediaDevices.getUserMedia({video: true});
    var firstAudioOutput = true;
    for (let i = 0; i !== deviceInfos.length; ++i) {
        const deviceInfo = deviceInfos[i];
        var mark = false;
        if (deviceInfo.kind === 'audioinput') {
            var schema = await mic_devices.$.elementPushPacketAsync(`
                <option id="opt">${ deviceInfo.label || 'mic' + (mic_devices.el.length+1) }</option>
            `);
            schema.el.opt.setAttribute("value",deviceInfo.deviceId);
            log(deviceInfo.kind + ": " + deviceInfo.label +
                " id = " + deviceInfo.deviceId);
            schema.el.opt.setAttribute("value",deviceInfo.deviceId);
            
        } else if (deviceInfo.kind === 'videoinput') {
            var schema = await video_devices.$.elementPushPacketAsync(`
                <option id="opt">${ deviceInfo.label || 'camera ' +
                (video_devices.el.length + 1) }</option>
            `)
            //alert(deviceInfo.deviceId);
            log(deviceInfo.kind + ": " + deviceInfo.label +
                " id = " + deviceInfo.deviceId);
            
                schema.el.opt.setAttribute("value",deviceInfo.deviceId);
        } else {
            mark = true;
        }

        if(deviceInfo.kind == "audiooutput") {
            var schema = await audio_output_devices.$.elementPushPacketAsync(`
                <option id="opt">${ deviceInfo.label || 'audioin ' +
                (audio_output_devices.el.length + 1) }</option>
            `)
            schema.el.opt.setAttribute("value",deviceInfo.deviceId);
            if(firstAudioOutput) {
                audio_output_devices.el.setAttribute("value",deviceInfo.deviceId);
                firstAudioOutput = false;
            }
            log(deviceInfo.kind + ": " + deviceInfo.label +
                " id = " + deviceInfo.deviceId);
        }
        if(mark) {
            log("OTHER:"+deviceInfo.kind + ": " + deviceInfo.label +
                " id = " + deviceInfo.deviceId);
        }
  }
}


var micNo = 0;
btnAddMic.el.addEventListener("click",async ()=>{
    //chkMic.el.style.display = "";

    const constraints = {
        audio : {
            deviceId : { exact : mic_devices.el.value }
        }
    };
    var schema = await mic_holder.$.elementPushPacketAsync(`
        <audio id="control"></audio>
    `);
    var audio_stream = null;
    try {
        audio_stream = schema.el.control.srcObject = await navigator.mediaDevices.getUserMedia(constraints);
    } catch(e) {
        audio_stream = schema.el.control.src = window.URL.createObjectURL(await navigator.mediaDevices.getUserMedia(constraints));
    }
    self.app.audio.layers.push({
        type : "audio",
        source : "mic",
        stream : audio_stream,
        el : schema.el.control
    });
    self.app.tracks.push({
        type : "audio",
        source : "mic",
        data : {
            name : "mic" + micNo
        },
        id : self.genId("TRACK0"),
        layer : self.app.audio.layers.length,
        events : []
    });
    micNo++;
    self.app.events.emit("updateTracks");
    // mic return
    //schema.el.control.play();
});

btnAddAudioFile.el.addEventListener("click",async ()=>{
    function addTrack(file) {
        var reader = new FileReader();
        reader.onload = async function(e) {
            var arrayBuffer = this.result;
            var type = file.type.indexOf("audio/") !=-1 ? "audio" : null;
            if(type == null) { console.log("not an audio file : " + file.name); return; }
            var audio = new AudioContext();
            var bufferSource = await audio.decodeAudioData(arrayBuffer);
            var track = {
                type : type,
                source : "file",
                id : self.genId("TRACK0"),
                data : {
                    mime : file.type,
                    name : file.name,
                    audio : audio,
                    buffer : bufferSource
                },
                events : []
            };
            fileAudio.el.value = "";
            self.app.tracks.push(track);
            console.log(track);
            self.app.events.emit("updateTracks");
        }
        reader.readAsArrayBuffer(file);
    }
    for(var x = 0; x < fileAudio.el.files.length;x++) {
        addTrack(fileAudio.el.files[x]);
    }
});


btnAddImageVideoFile.el.addEventListener("click",async ()=>{
    function addTrack(file) {
        var reader = new FileReader();
        reader.onload = async function(e) {
            var arrayBuffer = this.result;
            var type = file.type.indexOf("image/") !=-1 ? "image" : null;
            if(type != null) { 
                var img = new Image();
                var blob =  new Blob([arrayBuffer]);
                img.src = window.URL.createObjectURL(blob);
                var track = {
                    type : "video",
                    id : self.genId("TRACK0"),
                    data : {
                        mime : file.type,
                        name : file.name,
                        type : "image",
                        blob,
                        el : img
                    },
                    events : []
                };
                fileImage.el.value = "";
                self.app.tracks.push(track);
                console.log(track);
                self.app.events.emit("updateTracks");
            } else {
                type = file.type.indexOf("video/") != -1 ? "video" : null;
                if(type != null) {
                    var blob = new Blob([arrayBuffer]);
                    var video = document.createElement("video");
                    video.src = window.URL.createObjectURL(blob);
                    var stream = video.captureStream();
                    console.log("video file : " + file.name);
                    var track = {
                        type : "video",
                        id : self.genId("TRACK0"),
                        data : {
                            mime : file.type,
                            name : file.name,
                            type : "clip",
                            stream,
                            el : video
                        },
                        events : []
                    };
                    video.play();
                    self.app.tracks.push(track);
                    console.log(track);
                    self.app.events.emit("updateTracks");
                } else {
                    var ext = "";
                    if(file.name.length >= 4) {
                        ext = file.name.substring(file.name.length-4);
                    }
                    if(ext == ".ncp") {
                        // may check for version and signature, to handle/bind private data of author.
                        throw new Error("not implemented external ncp files. contact an especialist.");
                    } else {
                        console.log("not an image/video file : " + file.name + " : " + file.type); return; 
                    }
                    
                }
            }
        }
        reader.readAsArrayBuffer(file);
    }
    for(var x = 0; x < fileImage.el.files.length;x++) {
        addTrack(fileImage.el.files[x]);
    }

});
var textNb = 0;
btnAddText.el.addEventListener("click",()=>{
    var track = {
        type : "video",
        id : self.genId("TRACK0"),
        data : {
            name : "text" + textNb,
            type : "text",
            value : ""
        },
        events : []
    }
    textNb++;
    self.app.tracks.push(track);
    self.app.events.emit("updateTracks");
});

cameraDevice = null;
/*
btnSetCamera.el.addEventListener("click",async ()=>{

    chkScreen.el.style.display = "none";
    chkCanvas.el.style.display = "none";
    chkCamera.el.style.display = "";
    
    if(self.app.video.mode == "play") {
        recordHolder.el.style.display = "";
        playscreen.el.style.display = "none";
    }
    self.app.video.mode = "camera";

    cameraDevice = schema.el.control;
});
*/
var cameraNb = 0;
btnAddCamera.el.addEventListener("click",async ()=>{

    const constraints = {
        video: {
            deviceId: { exact : video_devices.el.value }
        }
    };
    var videoel = document.createElement("video");
    var stream = null;
    try {
        stream = videoel.srcObject = await navigator.mediaDevices.getUserMedia(constraints);
    } catch (error) {
        stream = videoel.src = window.URL.createObjectURL(await navigator.mediaDevices.getUserMedia(constraints));
    }
    document.body.appendChild(videoel);
    videoel.style.display = "none";
    videoel.play();
    var track = {
        type : "video",
        id : self.genId("TRACK0"),
        data : {
            name : "camera" + cameraNb,
            type : "camera",
            stream : stream,
            el : videoel
        },
        events : []
    };
    cameraNb++;
    self.app.tracks.push(track);
    console.log(track);
    self.app.events.emit("updateTracks");
});

/*
btnSetScreen.el.addEventListener("click",async ()=>{
    chkScreen.el.style.display = "";
    chkCanvas.el.style.display = "none";
    chkCamera.el.style.display = "none";

    
    

    if(cameraDevice) {
        cameraDevice.pause();
        stream.getTracks().forEach(function(track) {
          track.stop();
        });
        cameraDevice.style.display = "none";
        camera_holder.$.elementsClear();
    }

    if(self.app.video.mode == "play") {
        recordHolder.el.style.display = "";
        playscreen.el.style.display = "none";
    }
    self.app.video.mode = "desktop";

    stream.getTracks().forEach((track)=>{
        track.onended = function(event) {
            log("end of screen capture");
            chkScreen.el.style.display = "none";
            stopRecording();
        }
    });

    schema.el.control.play();
    cameraDevice = schema.el.control;
});
*/
var screenNb = 0;
btnAddScreen.el.addEventListener("click",async ()=>{
    const constraints = { video : true };
    var videoel = document.createElement("video");
    var stream = null;
    if (navigator.getDisplayMedia) {
        stream = videoel.srcObject = await navigator.getDisplayMedia(constraints);
    } else if (navigator.mediaDevices.getDisplayMedia) {
        stream = videoel.srcObject = await navigator.mediaDevices.getDisplayMedia(constraints);
    } else {
        stream = videoel.srcObject = await navigator.mediaDevices.getUserMedia({video: {mediaSource: 'screen'}});
    }
    videoel.play();

    var track = {
        type : "video",
        id : self.genId("TRACK0"),
        data : {
            name : "screen"+screenNb,
            type : "screen",
            stream : stream,
            el : videoel
        },
        events : []
    };
    screenNb++;
    self.app.tracks.push(track);
    console.log(track);
    self.app.events.emit("updateTracks");

});

btnSetVideoNone.el.addEventListener("click",()=>{

    chkScreen.el.style.display = "none";
    chkCanvas.el.style.display = "none";
    chkCamera.el.style.display = "none";


    if(cameraDevice) {
        cameraDevice.pause();
        stream.getTracks().forEach(function(track) {
          track.stop();
        });
        cameraDevice.style.display = "none";
        camera_holder.$.elementsClear();
    }

    if(self.app.video.mode == "play") {
        recordHolder.el.style.display = "";
        playscreen.el.style.display = "none";
    }

    self.app.video.mode = "none";
    camera_holder.$.elementsClear();
    playscreen.el.style.display = "none";  
    
});
btnSetAudioNone.el.addEventListener("click",()=>{
    
    

    for(var x = 0; x < self.app.audio.layers.length;x++) {
        var layer  = self.app.audio.layers[x];
        layer.stream.getTracks().forEach((track)=>{
            track.stop();
        });
    }
    self.app.audio.layers.splice(0,self.app.audio.layers.length);
    /*
    if(audioStream0) audioStream0.getTracks().forEach((track)=>{
        track.stop();
    })
    */
});


let mediaRecorder;
let recordedBlobs = [];
let sourceBuffer;

const mediaSource = new MediaSource();
mediaSource.addEventListener('sourceopen', function handleSourceOpen(event) {
    log('MediaSource opened');
    sourceBuffer = mediaSource.addSourceBuffer('video/webm; codecs="vp8"');
    log('Source buffer: ', sourceBuffer);
}, false);

log('Started stream capture from canvas element: '+ stream);




function toggleRecording() {
    if (btnRecord.el.textContent === 'start recording') {
        startRecording();
    } else {
        stopRecording();
        btnRecord.el.textContent = 'start recording';
        btnPlay.el.disabled = false;
        btnDownloadMovie.el.disabled = false;
    }
}


function handleDataAvailable(event) {
    
    if (event.data && event.data.size > 0) {
        console.log("DATA",event.data);
        recordedBlobs.push(event.data);
    } else {
        //console.log( mediaRecorder.requestData() );
        //console.log(event);
    }
}

async function handlePause(event) {
    log('Recorder paused: ', event);
}
async function handleStop(event) {
    log('Recorder stopped: ', event);
    await self.app.audio.ctx.close();

    for(var x = 0; x < self.app.audio.recordTracks.length;x++) {
        console.log("removing tracks");
        stream.removeTrack(self.app.audio.recordTracks[x]);
    }
    if(self.app.video.mode == "none") {
        const superBuffer = new Blob(recordedBlobs, {type: 'audio/webm'});
        var url = (window.URL || window.webkitURL).createObjectURL(superBuffer);
        var schema = await playaudio.$.elementSetPacketAsync(`
            <audio id="audio" controls>
                <source src="`+url+`" type="audio/webm">
                Your browser does not support the audio tag.
            </audio>
        `);
        self.app.audio.control = schema.el.audio;
        
        delete self.app.events.hitTrack;
    } else {
        const superBuffer = new Blob(recordedBlobs, {type: 'video/webm'});
        playscreen.el.src = window.URL.createObjectURL(superBuffer);
        
    }
    
    self.app.recordState = "stopped";
}




// The nested try blocks will be simplified when Chrome 47 moves to Stable
async function startRecording() { // take 'stream' to MediaRecorder, to setup stream go to 'updateTracks'
    if(!self.app.hasVideoTracks() && !self.app.hasAudioTracks()) {
        throw new Error("(you must select some input device)");
        return;
    }

    recordHolder.el.style.display = "";
    recordedBlobs = [];
    if(self.app.events.hitTrack)
        self.app.events.off("hitTrack",self.app.events.hitTrack);

    var audioCtx = new AudioContext();
    self.app.audio.ctx = audioCtx;
    self.app.audio.recordTracks = [];

    var audioMixer = audioCtx.createMediaStreamDestination();

    for(var x = 0; x < self.app.audio.layers.length;x++) {
        var layer = self.app.audio.layers[x];
        layer.device = {};
        layer.device.source = audioCtx.createMediaStreamSource(layer.stream);
        layer.device.gain = audioCtx.createGain();
        layer.device.source.connect(layer.device.gain);
        layer.device.gain.gain.value = 0.5;
        layer.device.gain.connect(audioMixer);
    }

    if(self.app.hasAudioTracks()) {
        self.app.events.hitTrack = (n)=>{
            if(n < self.app.tracks.length && self.app.tracks[n].type == "audio") {
                var playback = audioCtx.createBufferSource();
                var playbackGain = audioCtx.createGain();
                playback.buffer = self.app.tracks[n].data.buffer;
                playback.connect(playbackGain);
                playbackGain.gain.value = 0.5;
                playbackGain.connect(audioMixer);
                playback.connect(audioCtx.destination);
                playback.start();
            }
            console.log("hit",self.app.tracks[n]);
        };
        self.app.events.on("hitTrack",self.app.events.hitTrack);

        // null signal to record empty audio space if mic is not activated
        var myArrayBuffer = audioCtx.createBuffer(2, audioCtx.sampleRate, audioCtx.sampleRate);
        for (var channel = 0; channel < myArrayBuffer.numberOfChannels; channel++) {
            var nowBuffering = myArrayBuffer.getChannelData(channel);
            for (var i = 0; i < myArrayBuffer.length; i++) {
                nowBuffering[i] = 0;
            }
        }
        var source = audioCtx.createBufferSource();
        source.buffer = myArrayBuffer;
        source.connect(audioMixer);
        source.loop = true;
        source.start();

    }
    
    // mixing audio and video
    if( ( self.app.hasAudioTracks() ) && self.app.hasVideoTracks() ) {
        console.log("MIXED IN AUDIO AND VIDEO");
        audioMixer.stream
            .getAudioTracks()
            .forEach((audioTrack) => {
                self.app.audio.recordTracks.push(audioTrack);
                console.log(audioTrack);
                stream.addTrack(audioTrack);
            });
        
    }

    if( self.app.hasVideoTracks() ) {
        self.app.recordType = "video";
    } else {
        self.app.recordType = "audio";
    }

    var options = {};
    if(self.app.recordType == "video") {

        console.log("VIDEO RECORD TYPE");
        options.mimeType =  'video/webm';
        try {
            mediaRecorder = new MediaRecorder(stream, options);
        } catch (e0) {
            try {
                options.mimeType = 'video/webm,codecs=vp9';
                mediaRecorder = new MediaRecorder(stream, options);
            } catch (e1) {
                try {
                    options = 'video/vp8'; // Chrome 47
                    mediaRecorder = new MediaRecorder(stream, options);
                } catch (e2) {
                    log(`MediaRecorder is not supported by this browser.`);
                    log('Exception while creating MediaRecorder:'+ e2);
                    return;
                }
            }
        }
    } else {

        //stream = new MediaStream(stream.getAudioTracks());
        stream = audioMixer.stream;
        try {
            options.mimeType =  'audio/webm';
            mediaRecorder = new MediaRecorder(stream, options);
            
        } catch(e) {
            try {
                options.mimeType = 'audio/webm;codecs=opus';
                mediaRecorder = new MediaRecorder(stream, options);
                
            } catch(e1) {
                log(`Media Recorder is not supported by this browser.`);
                log('Exception while creating MediaRecorder:'+ e1);
                return;
            }
        }
    }

    log('Created MediaRecorder', mediaRecorder, 'with options', options);
    btnRecord.el.textContent = 'stop recording';
    btnPlay.el.disabled = true;
    btnDownloadMovie.el.disabled = true;
    mediaRecorder.onstop = handleStop;
    mediaRecorder.onpause = handlePause;
    mediaRecorder.ondataavailable = handleDataAvailable;
    mediaRecorder.onerror = function(error) {
        console.log(error.name);
        console.log(error);
    }
    self.app.recordState = "recording";
    mediaRecorder.start(1000/30);
    try {

    } catch(e) {
        log("error on media recorder start");
        log(e.message);
    }

    log('MediaRecorder started' + mediaRecorder);
}

function stopRecording() {
    if(mediaRecorder.state != "inactive") { 
        mediaRecorder.stop();    
    } else { // user stopped sharing screen.
        self.app.video.mode = "none";
        chkScreen.el.style.display = "none";
    }
    log('Recorded Blobs: '+ recordedBlobs.length);
    playscreen.el.controls = true;
}
async function download2() {
    var nblob = await makeNcpBlob(recordedBlobs);
    const url = window.URL.createObjectURL(nblob);
    const a = document.createElement('a');
    a.style.display = 'none';
    a.href = url;
    a.download = 'last_record.ncp';
    document.body.appendChild(a);
    a.click();
    setTimeout(() => {
        document.body.removeChild(a);
        window.URL.revokeObjectURL(url);
    }, 10000);
}


async function download() {
    if(false) {
        var nblob = await makeNcpBlob(recordedBlobs);
        const url = window.URL.createObjectURL(nblob);
        const a = document.createElement('a');
        a.style.display = 'none';
        a.href = url;
        a.download = 'last_record.ncp';
        document.body.appendChild(a);
        a.click();
        setTimeout(() => {
            document.body.removeChild(a);
            window.URL.revokeObjectURL(url);
        }, 10000);
    } else {
        var blob,type;
        if(self.app.video.mode=="none") {
            blob = new Blob(recordedBlobs, {type: 'audio/webm'});
            type = "audio.webm";
        } else {
            blob = new Blob(recordedBlobs, {type: 'video/webm'});
            type = "video.webm";
        }
        const url = window.URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.style.display = 'none';
        a.href = url;
        a.download = 'last_record.webm';
        document.body.appendChild(a);
        a.click();
        setTimeout(() => {
            document.body.removeChild(a);
            window.URL.revokeObjectURL(url);
        }, 10000);
    }
}
btnRecord.el.addEventListener("click",()=>{ toggleRecording(); });
btnPlay.el.addEventListener("click",()=>{ 

    playholder.el.style.display = "";
    recordHolder.el.style.display = "none";
    if(self.app.recordType == "audio") {
        playscreen.el.style.display = "none";
        self.app.audio.control.play();
        
    } else if(self.app.recordType == "video") {
        playscreen.el.style.display = "";
        playaudio.$.elementsClear();
        playscreen.el.style.width = "100%";
        playscreen.el.play();  
        self.app.video.mode = "play";
    }
});
btnDownloadMovie.el.addEventListener("click",()=>{ download(); });

async function makeNcpBlob(blobs) {
    var blob,type;
    if(self.app.video.mode=="none") {
        blob = new Blob(recordedBlobs, {type: 'audio/webm'});
        type = "audio.webm";
    } else {
        blob = new Blob(recordedBlobs, {type: 'video/webm'});
        type = "video.webm";
    }

    var config_str = JSON.stringify({
        version : [0,0,2],
        type : type,
        main : "webm"
    });
    var config_ab = Binary.str2utf8ab(config_str);
    var webm_ab = await blob.arrayBuffer()
    var ncp_blob = new Blob( 
        new BinaryWriter().u32(config_ab.byteLength).data.concat([config_ab]) 
            .concat(
                new BinaryWriter().u32(webm_ab.byteLength).data.concat([webm_ab])
            ),
        {mime:"application/ncp"}
    );
    return ncp_blob;
}

btnSend.el.addEventListener("click",async ()=>{
    var nblob = await makeNcpBlob(recordedBlobs);
    Import({url:"/send",method:"POST",type:Import.Binary,data : nblob })
    .done((data)=>{
        console.log(data);
        var json = JSON.parse(data);
        if(!json.result) {
            alert("can't save this record, interrupted on server.");
            return;
        }
        refresh_list(true);
    })
    .send();
});

var template = { // default ms pip grid
    pipGrid : [2,2],
    pipPos : [1,1]
};

var keyboard = {
    ctrl : false,
    shift : false,
}
window.addEventListener("keydoown",(e)=>{
    //console.log(e.keyCode);
    if(e.keyCode == 16) {
        keyboard.shift = true;
    }
    if(e.keyCode == 17) {
        keyboard.ctrl = true;
    }

});
window.addEventListener("keyup",(e)=>{
    //console.log(e.keyCode);
    if(e.keyCode == 37) {
        if(template.pipPos[0] > 0 ) {
            template.pipPos[0] -= 1;
            if(template.pixi) {
                console.log("call new pip");
                template.pipChanged = true;
                self.app.events.emit("pipChange",[{pixi:template.pixi,res:template.videoOutputSize,force:true}]);
            }
        }
        
    } else if(e.keyCode == 38) {
        if(template.pipPos[1] > 0 ) {
            template.pipPos[1] -= 1;
            if(template.pixi) {
                console.log("call new pip");
                template.pipChanged = true;
                self.app.events.emit("pipChange",[{pixi:template.pixi,res:template.videoOutputSize,force:true}]);
            }
        }

    } else if(e.keyCode == 39) {
        if(template.pipPos[0] < template.pipGrid[0]-1) {
            template.pipPos[0] += 1;
            if(template.pixi) {
                console.log("call new pip");
                template.pipChanged = true;
                self.app.events.emit("pipChange",[{pixi:template.pixi,res:template.videoOutputSize,force:true}]);
            }
        }
    } else if(e.keyCode == 40) {
        if(template.pipPos[1] < template.pipGrid[1]-1) {
            template.pipPos[1] += 1;
            if(template.pixi) {
                console.log("call new pip");
                template.pipChanged = true;
                self.app.events.emit("pipChange",[{pixi:template.pixi,res:template.videoOutputSize,force:true}]);
            }
        }
    }

    

    if(e.keyCode == 16) {
        keyboard.shift = false;
    }
    if(e.keyCode == 17) {
        keyboard.ctrl = false;
    }
});


self.app.events.on("msChange",(context)=>{
    // after ms track
    if("msTrack" in self.app.video) {
        var pixi = context.pixi;
        
        var track = self.app.tracks[self.app.video.layers[0].track];
        if(self.app.video.layers[0].lastTrack!=self.app.video.layers[0].track) {
            msChanged = true;
            if(track.type == "video") {
                if(track.data.type == "clip") {
                    console.log("clip");
                    track.data.el.currentTime= 0;
                    track.data.el.play();
                    var f = ()=>{
                        lastTrack = -1;
                        track.data.el.removeEventListener("ended",self.app.video.clip.handler);
                    };
                    self.app.video.clip = {
                        handler : f
                    };
                    track.data.el.addEventListener("ended",f);
                } else if(track.data.type == "text") {
                    console.log("text");
                    var style = track.data.style ? track.data.style : new PIXI.TextStyle({
                        fontFamily: 'Arial',
                        fontSize: 40,
                        fontStyle: 'italic',
                        fontWeight: 'bold',
                        fill: ['#ffffff', '#00ff99'], // gradient
                        stroke: '#4a1850',
                        strokeThickness: 3,
                        dropShadow: true,
                        dropShadowColor: '#000000',
                        dropShadowBlur: 2,
                        dropShadowAngle: Math.PI / 6,
                        dropShadowDistance: 2,
                        wordWrap: true,
                        wordWrapWidth: 440,
                    });
                    track.data.style = style;
                    if(template.msSprite) {
                        pixi.stage.removeChild(template.msSprite);
                        template.msSprite.destroy();
                        template.msSprite = null;
                    }
                    template.msSprite = new PIXI.Text(track.data.value, style);
                    template.msSprite.width = pixi.screen.width/2;
                    template.msSprite.height = 200;
                    template.msSprite.x = pixi.screen.width/4;
                    template.msSprite.y = pixi.screen.height/2-100;
                    pixi.stage.addChild(template.msSprite);
                    track.data.oldValue = track.data.value;
                } 

                if(track.data.type == "camera" || track.data.type == "screen" || track.data.type == "clip" || track.data.type == "image") {
                    var texture = track.data.texture ? track.data.texture : PIXI.Texture.from(track.data.el);
                    track.data.texture = texture;
                    if(template.msSprite) {
                        pixi.stage.removeChild(template.msSprite);
                        template.msSprite.destroy();
                        template.msSprite = null;
                    }
                    template.msSprite = new PIXI.Sprite(texture);
                    template.msSprite.x = 0;
                    template.msSprite.y = 0;
                    template.msSprite.width = pixi.screen.width;
                    template.msSprite.height = pixi.screen.height;
                    pixi.stage.addChild(template.msSprite);
                }
            }

            self.app.video.layers[0].lastTrack = self.app.video.layers[0].track;
            //lastTrack = self.app.video.msTrack;
        }
    }
});
self.app.events.on("pipChange",(context)=>{
    // after pip track
    var pixi = context.pixi;
    var videoOutputSize = context.res;
    var msChanged = context.msChanged;
    var force = !! context.force;
    template.pixi = pixi;
    template.videoOutputSize = videoOutputSize;
    var nsz = [videoOutputSize[0]/template.pipGrid[0], videoOutputSize[1]/template.pipGrid[1]];
    var track = self.app.tracks[self.app.video.pipTrack];
    if("pipTrack" in self.app.video && self.app.video.pipTrack!=-1) {
        //console.log("pip almost",context.force,template.lastPipTrack!=self.app.video.pipTrack,msChanged);
        if(!!template.pipChanged || template.lastPipTrack!=self.app.video.pipTrack || msChanged) {
            template.pipChanged = false;
            if(track.type == "video") {
                if(track.data.type == "clip") {
                    console.log("clip");
                    track.data.el.currentTime= 0;
                    track.data.el.play();
                    var f = ()=>{
                        lastTrack = -1;
                        track.data.el.removeEventListener("ended",self.app.video.clip.handler);
                    };
                    self.app.video.clip = {
                        handler : f
                    };
                    track.data.el.addEventListener("ended",f);
                } else if(track.data.type == "text") {
                    console.log("text0");
                    var style = track.data.style ? track.data.style : new PIXI.TextStyle({
                        fontFamily: 'Arial',
                        fontSize: 40,
                        fontStyle: 'italic',
                        fontWeight: 'bold',
                        fill: ['#eaff00', '#00ff99'], // gradient
                        stroke: '#4a1850',
                        strokeThickness: 3,
                        dropShadow: true,
                        dropShadowColor: '#000000',
                        dropShadowBlur: 2,
                        dropShadowAngle: Math.PI / 6,
                        dropShadowDistance: 2,
                        wordWrap: true,
                        wordWrapWidth: 440,
                    });
                    track.data.style = style;
                    if(template.pipSprite) {
                        //console.log("removed old ms");
                        pixi.stage.removeChild(template.pipSprite);
                        template.pipSprite.destroy();
                        template.pipSprite = null;
                    }
                    
                    template.pipSprite = new PIXI.Text(track.data.value, style);
                    template.pipSprite.width = nsz[0];
                    template.pipSprite.height = nsz[1];
                    template.pipSprite.x = template.pipPos[0]*nsz[0];
                    template.pipSprite.y = template.pipPos[1]*nsz[1];
                    pixi.stage.addChild(template.pipSprite);
                    track.data.oldValue = track.data.value;
                } 
                if(track.data.type == "camera" || track.data.type == "screen" || track.data.type == "clip" || track.data.type == "image") {
                    var texture = track.data.texture ? track.data.texture : PIXI.Texture.from(track.data.el);
                    track.data.texture = texture;
                    if(template.pipSprite) {
                        pixi.stage.removeChild(template.pipSprite);
                        template.pipSprite.destroy();
                        template.pipSprite = null;
                    }
                    template.pipSprite = new PIXI.Sprite(texture);
                    template.pipSprite.x = template.pipPos[0]*nsz[0];
                    template.pipSprite.y = template.pipPos[1]*nsz[1];
                    template.pipSprite.width = nsz[0];
                    template.pipSprite.height = nsz[1];
                    pixi.stage.addChild(template.pipSprite);
                    // old version run every frame
                    // ctx.drawImage(track.data.el, 0, 0, track.data.el.videoWidth, track.data.el.videoHeight, 3*nsz[0] - 0.1*nsz[0],3*nsz[1]-0.1*nsz[0], nsz[0], nsz[1]);

                }
            }
        }
    }

    
});
self.app.events.on("updateTracks",async ()=>{
    // do not remove duplicate tracks cause it may be same track name for different folders
    console.log("update tracks");
    function setLayerChangeHandler(layer,x) {
        self.app.events.off("layer_"+layer.name+"_change",layer.change);
        layer.change = (context)=> {
            var pixi = context.pixi;
            var track = self.app.tracks[self.app.video.layers[x].track];
            if(self.app.video.layers[x].lastTrack!=self.app.video.layers[x].track) { // update on layer
                if(track.type == "video") {
                    if(track.data.type == "clip") {
                        console.log("clip");
                        track.data.el.currentTime= 0;
                        track.data.el.play();
                        var f = ()=>{
                            self.app.video.layers[x].lastTrack = -1; // loop clip
                            track.data.el.removeEventListener("ended",self.app.video.clip.handler);
                        };
                        self.app.video.clip = {
                            handler : f
                        };
                        track.data.el.addEventListener("ended",f);
                    } else if(track.data.type == "text") {
                        console.log("text");
                        var style = track.data.style ? track.data.style : new PIXI.TextStyle({
                            fontFamily: 'Arial',
                            fontSize: 40,
                            fontStyle: 'italic',
                            fontWeight: 'bold',
                            fill: ['#ffffff', '#00ff99'], // gradient
                            stroke: '#4a1850',
                            strokeThickness: 3,
                            dropShadow: true,
                            dropShadowColor: '#000000',
                            dropShadowBlur: 2,
                            dropShadowAngle: Math.PI / 6,
                            dropShadowDistance: 2,
                            wordWrap: true,
                            wordWrapWidth: 440,
                        });
                        track.data.style = style;
                        if(self.app.video.layers[x].msSprite) {
                            pixi.stage.removeChild(self.app.video.layers[x].msSprite);
                            self.app.video.layers[x].msSprite.destroy();
                            self.app.video.layers[x].msSprite = null;
                        }
                        self.app.video.layers[x].msSprite = new PIXI.Text(track.data.value, style);
                        self.app.video.layers[x].msSprite = pixi.screen.width/2;
                        self.app.video.layers[x].msSprite = 200;
                        self.app.video.layers[x].msSprite.x = pixi.screen.width/4;
                        self.app.video.layers[x].msSprite.y = pixi.screen.height/2-100;
                        pixi.stage.addChild(self.app.video.layers[x].msSprite);
                        track.data.oldValue = track.data.value;
                    }
                    if(track.data.type == "camera" || track.data.type == "screen" || track.data.type == "clip" || track.data.type == "image") {
                        var texture = track.data.texture ? track.data.texture : PIXI.Texture.from(track.data.el);
                        track.data.texture = texture;
                        if(self.app.video.layers[x].msSprite) {
                            pixi.stage.removeChild(self.app.video.layers[x].msSprite);
                            self.app.video.layers[x].msSprite.destroy();
                            self.app.video.layers[x].msSprite = null;
                        }
                        self.app.video.layers[x].msSprite = new PIXI.Sprite(texture);
                        self.app.video.layers[x].msSprite.x = 0;
                        self.app.video.layers[x].msSprite.y = 0;
                        self.app.video.layers[x].msSprite.width = pixi.screen.width;
                        self.app.video.layers[x].msSprite.height = pixi.screen.height;
                        pixi.stage.addChild(self.app.video.layers[x].msSprite);
                    }
                }

            }
        };
        self.app.events.on("layer_"+layer.name+"_change",layer.change);
    }
    var layerButtons = [];
    for(var x = 0; x < self.app.video.layers.length;x++) {
        var layer = self.app.video.layers[x];
        layerButtons.push(`<div style="padding-left:5px;padding-right:5px;"><button id="btnLayer_${x}">${layer.name}</button></div>`);
        setLayerChangeHandler(layer,x);
    }
    layerButtons = layerButtons.join("");
    

    // make a track from channel template selected.
    async function addTrack(n,track) {
        if(!track.loaded) {
            console.log(track);
            track.loaded = true;
            track.data.live = []; // mark which layers are transmiting the content.
            if(track.type == "audio") {
                if(track.source == "file") {
                    var schema = await tracksView.$.elementPushPacketAsync(`
                        <div style="display:flex;">
                            <div style="padding-left:5px;padding-right:5px;">🔊 ${(""+n).padStart(2,"0")}</div>
                            <div style="padding-left:5px;padding-right:5px;width:100px;overflow:hidden;white-space: nowrap;">${track.data.name}</div>
                            <div style="padding-left:5px;padding-right:5px;"><button id="btnHit">hit</button></div>
                        </div>
                    `);
                    schema.el.btnHit.addEventListener("click",()=>{
                        self.app.events.emit("hitTrack",[n]);
                    });
                } else if(track.source == "mic") {
                    var schema = await tracksView.$.elementPushPacketAsync(`
                        <div style="display:flex;">
                            <div style="padding-left:5px;padding-right:5px;">🔊 ${(""+n).padStart(2,"0")}</div>
                            <div style="padding-left:5px;padding-right:5px;width:100px;overflow:hidden;white-space: nowrap;">${track.data.name}</div>
                        </div>
                    `);
                }

            } else if(track.type == "video") {
                if(track.data.type == "text") {
                    var schema = await tracksView.$.elementPushPacketAsync(`
                        <div style="display:flex;">
                            <div style="padding-left:5px;padding-right:5px;">🔊 ${(""+n).padStart(2,"0")}</div>
                            <div style="padding-left:5px;padding-right:5px;width:100px;overflow:hidden;white-space: nowrap;">${track.data.name}</div>
                            <div><input id="txtValue" type="text"/></div>
                            ${layerButtons}
                        </div>
                    `);
                    schema.el.txtValue.addEventListener("change",()=>{
                        track.data.value = schema.el.txtValue.value;
                    });
                    schema.el.txtValue.addEventListener("keyup",(e)=>{
                        if(self.app.video.pipTrack== n && template.pixi) {
                            track.data.value = schema.el.txtValue.value;
                            template.pipChanged = true;
                            // realtime text change if pip layer
                            self.app.events.emit("pipChange",[{pixi:template.pixi,res:template.videoOutputSize,force:true}]);
                        }
                    });
                    function setHandler(schema,layer,x) {
                        schema.el["btnLayer_" + x].addEventListener("click",()=>{ // works like any pip layer
                            var found = false;
                            var sel_remove = [];
                            for(var y = 0; y < track.data.live.length;y++) {
                                if(track.data.live[y].name == layer.name) {
                                    found = true;
                                    layer.track = n;
                                    if(layer.track == n) { // on/off track
                                        layer.lastTrack = layer.track;
                                        layer.track = -1;
                                        sel_remove.push(y);
                                    } else {
                                        layer.lastTrack = layer.track;
                                        layer.track = n;
                                    }
                                    break;
                                }
                            }
                            for(var y = sel_remove.length-1;y>=0;y--) {
                                track.data.live.splice(sel_remove[y],1);
                            }
                            if(!found) {
                                track.data.live.push({name : layer.name });
                                layer.lastTrack = layer.track;
                                layer.track = n;
                            }
                            if(self.app.recordState == "stopped") {
                                recordHolder.el.style.display = "";
                            }
                            self.app.events.emit("layer_"+layer.name+"_hit",[n]);
                        });
                    }
                    for(var x = 0; x < self.app.video.layers.length;x++) {
                        var layer = self.app.video.layers[x];
                        setHandler(schema,layer,x);
                    }
                    schema.el.btnLayer_0.addEventListener("click",()=>{
                        self.app.events.emit("msTrack",[n]);
                    });
                    schema.el.btnLayer_1.addEventListener("click",()=>{
                        self.app.events.emit("pipTrack",[n]);
                    });
                } else {
                    var schema = await tracksView.$.elementPushPacketAsync(`
                        <div style="display:flex;">
                            <div style="padding-left:5px;padding-right:5px;">🔊 ${(""+n).padStart(2,"0")}</div>
                            <div style="padding-left:5px;padding-right:5px;width:100px;overflow:hidden;white-space: nowrap;">${track.data.name}</div>
                            ${layerButtons}
                        </div>
                    `);
                    function setHandler(schema,layer,x) {
                        schema.el["btnLayer_" + x].addEventListener("click",()=>{ // works like any pip layer
                            var found = false;
                            var sel_remove = [];
                            for(var y = 0; y < track.data.live.length;y++) {
                                if(track.data.live[y].name == layer.name) {
                                    found = true;
                                    layer.track = n;
                                    if(layer.track == n) { // on/off track
                                        layer.lastTrack = layer.track;
                                        layer.track = -1;
                                        sel_remove.push(y);
                                    } else {
                                        layer.lastTrack = layer.track;
                                        layer.track = n;
                                    }
                                    break;
                                }
                            }
                            for(var y = sel_remove.length-1;y>=0;y--) {
                                track.data.live.splice(sel_remove[y],1);
                            }
                            if(!found) {
                                track.data.live.push({name : layer.name });
                                layer.lastTrack = layer.track;
                                layer.track = n;
                            }
                            if(self.app.recordState == "stopped") {
                                recordHolder.el.style.display = "";
                            }
                            self.app.events.emit("layer_"+layer.name+"_hit",[n]);
                        });
                    }
                    for(var x = 0; x < self.app.video.layers.length;x++) {
                        var layer = self.app.video.layers[x];
                        setHandler(schema,layer,x);
                    }
                    schema.el.btnLayer_0.addEventListener("click",()=>{
                        self.app.events.emit("msTrack",[n]);
                    });
                    schema.el.btnLayer_1.addEventListener("click",()=>{
                        self.app.events.emit("pipTrack",[n]);
                    });
                }

            } else if(track.type == "image") {
                var schema = await tracksView.$.elementPushPacketAsync(`
                    <div style="display:flex;">
                        <div style="padding-left:5px;padding-right:5px;">🔊 ${(""+n).padStart(2,"0")}</div>
                        <div style="padding-left:5px;padding-right:5px;width:100px;overflow:hidden;white-space: nowrap;">${track.data.name}</div>
                        <div style="padding-left:5px;padding-right:5px;"><button id="btnHit">MS</button></div>
                    </div>
                `);
                schema.el.btnHit.addEventListener("click",()=>{
                    self.app.events.emit("msTrack",[n]);
                });

            }
        }
    }

    if(self.app.tracks.length>0) lblTracks.el.style.display = "";
    else lblTracks.el.style.display = "none";
    for(var x =0; x < self.app.tracks.length;x++) {
        addTrack(x,self.app.tracks[x]);
    }

    if(self.app.hasVideoTracks() && !self.app.video.output.init) {
        self.app.video.output.init = true;
        console.log("INIT VIDEO",self.app.hasVideoTracks(), self.app.video.output.init);
        recordHolder.el.style.display = "";
        var schema = await camera_holder.$.elementSetPacketAsync(`
            <div id="mockWidth"></div>
            <canvas id="videoOutput" style="border:solid 1px #000;background-color:#000;"></canvas>
        `);
        var videoOutputSize = [parseInt(screenWidth.el.value),parseInt(screenHeight.el.value)];
        schema.el.videoOutput.setAttribute("width",videoOutputSize[0]);
        schema.el.videoOutput.setAttribute("height",videoOutputSize[1]);
        if(videoOutputSize[0] < schema.el.mockWidth.offsetWidth) {
            schema.el.videoOutput.style.width = videoOutputSize[0] + 'px';
        } else {
            schema.el.videoOutput.style.width = "100%";
        }
        var pixi = self.app.video.pixi = new PIXI.Application({
            width: videoOutputSize[0], 
            height: videoOutputSize[1],
            transparent: true,
            view : schema.el.videoOutput
        });

        self.app.video.canvasFlag = true;
        var lastTrack = -1;
        template.lastPipTrack = -1;
        self.app.video.outputLoop = async function() {
            if(!self.app.video.canvasFlag) return;
            console.log("loop");
            var msChanged = false;

            // loop video layers to call ctors of each channel
            self.app.events.emit("msChange",[{pixi:pixi,res:videoOutputSize,first:true}]);
            self.app.events.emit("pipChange",[{pixi:pixi,res:videoOutputSize,msChanged}]);
            console.log("pipTrack",self.app.video.pipTrack == -1);
            if("pipTrack" in self.app.video && self.app.video.pipTrack == -1 && template.lastPipTrack != -1) { // clear pip from ms;
                console.log("pipTrackRemove0");
                if(template.pipSprite) {
                    pixi.stage.removeChild(template.pipSprite);
                    template.pipSprite.destroy();
                    template.pipSprite = null;
                }
                template.lastPipTrack = self.app.video.pipTrack;
            }
            template.lastPipTrack = self.app.video.pipTrack;

            setTimeout(()=>{
                self.app.video.outputLoop();
            },10);
        };
        self.app.video.outputLoop();
        self.app.stream = stream = schema.el.videoOutput.captureStream(60);
        self.app.video.mode = "play";
    } 
});

self.app.events.on("msTrack",(n)=>{
    self.app.video.layers[0].track = n;
    self.app.video.msTrack = n;
    if(self.app.recordState == "stopped") {
        recordHolder.el.style.display = "";
    }
    // if track is text show panel, else hide
});
self.app.events.on("pipTrack",(n)=>{
    if(self.app.video.pipTrack == n) {
        self.app.video.pipTrack = -1;
    } else {
        self.app.video.pipTrack = n;
    }
    if(self.app.recordState == "stopped") {
        recordHolder.el.style.display = "";
    }
    // if track is text show panel, else hide
});


async function addAsset(item) {
    var visible = false;
    var itemStruct = {
        init : false,
        data : item
    };
    var schema1 = await schema.$.list.elementUnshiftPacketAsync(`
        <tr style="cursor:pointer;">
            <td id="item">📼 ${item.id}</td>
            <td>🔽<a href="/messages/user1/${item.file}.ncp" download>download</a></td>
            <td id="addAsTrack">📌 add as track</td>
        </tr>
        <Component id="holder"></Component>
    `);
    itemStruct.schema1 = schema1;
    schema1.el.item.addEventListener("click",async ()=>{
        if(!visible) {
            if(!itemStruct.init) {
                itemStruct.init = true;
                var url = `/messages/user1/${item.file}.ncp`;

                var data = await fetch(url);
                var blob = await data.blob();
                var schema2 = await schema1.$.holder.elementPushPacketAsync(`
                    <tr id="view">
                        <td colspan="3" align="center">
                            <div>📅 ${item.date}</div>
                            <Component id="ncp" src="ncp.super" data={{this.src}}></Component>
                            <div id="sc"></div>
                        </td>
                    </tr>
                `,{context:{src:blob}});
                itemStruct.schema2 = schema2;
                schema2.el.sc.scrollIntoView({block:"center"});S
                schema2.exports.ncp.control.el.play();
                if( schema2.exports.ncp.spec.type == "audio.webm" ) {

                } else if(schema2.exports.ncp.spec.type == "video.webm") { // video tag, expecting bad margin, 100% width is custom
                    schema2.exports.ncp.control.el.style.width = "100%";
                    schema2.exports.ncp.control.el.style.marginBottom = "-7px";
                }
            } else {
                itemStruct.schema2.el.view.style.display = "";
                itemStruct.schema2.el.sc.scrollIntoView({block:"center"});
                itemStruct.schema2.exports.ncp.control.el.play();
            }
            
            visible = true;
        } else {
            itemStruct.schema2.el.view.style.display = "none";
            visible = false;
        }
    });
    var clipNb = 0;
    schema1.el.addAsTrack.addEventListener("click",async ()=>{
        console.log("addAsTrack");
        var data = await fetch(`/messages/user1/${item.file}.ncp`);
        var blob = await data.blob();
        async function load() {

            var file_ab = await this.props.data.arrayBuffer();
            var br = new BinaryReader(this.props.data,file_ab);
            var sz = br.u32();
            var config_blob = br.toBlob(sz);
            var config_ab = await config_blob.arrayBuffer();
            var json_str = Binary.utf8ab2str(config_ab,config_ab.byteLength);
            this.spec = JSON.parse(json_str);

            // bound to 0.0.1
            if( this.spec.type == "audio.webm" ) {
                var sz2 = br.u32();
                var webm_blob = br.toBlob(sz2);
                // change by this point compared to control
                var arrayBuffer = await webm_blob.arrayBuffer();
                var audio = new AudioContext();
                var bufferSource = await audio.decodeAudioData(arrayBuffer);
                var track = {
                    type : "audio",
                    id : self.genId("TRACK0"),
                    data : {
                        mime : "application/ncp",
                        name : item.file + ".ncp",
                        audio : audio,
                        buffer : bufferSource
                    },
                    events : []
                };
                self.app.tracks.push(track);
                self.app.events.emit("updateTracks");
                console.log(track);
            } else if(this.spec.type == "video.webm") {

                var sz2 = br.u32();
                var webm_blob = br.toBlob(sz2);

                var videoel = document.createElement("video");
                var url = URL.createObjectURL(webm_blob);
                videoel.src = url;
                videoel.play();
                var stream = videoel.captureStream();//videoel.srcObject = await webm_blob.stream();
                var track = {
                    type : "video",
                    id : self.genId("TRACK0"),
                    data : {
                        name : "clip" + clipNb,
                        type : "clip",
                        stream : stream,
                        el : videoel
                    },
                    events : []
                }
                clipNb++;
                self.app.tracks.push(track);
                self.app.events.emit("updateTracks");
                console.log(track);
            }
            // end bound
        }
        load.apply({props:{data:blob}}); // to reuse this.zip same as ncp.super
    });
}



</script>
