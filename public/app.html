<script>
    this.fail = false;
    var self = this;
    try {
        var a = await fetch("/ping",{method:"POST"});
        if(a.status==404) {
            this.fail = true;
            self.props.fail();
        }
    } catch(e) {
        this.fail = true;
        self.props.fail();
    }
</script>
<style>
    body {
        margin:0px;
    }
</style>
<div style="display:flex;background-color:navy;color:white;padding:10px;">
    <div>🧊 NumberCooler Recorder Premium</div>
</div>
<div id="main" style="display:flex;padding:0px;border-left:solid 10px navy;border-right:solid 10px navy;">
    <div id="listPanel" style="flex:0.6;overflow:auto;">
        <div id="listPanelMock"></div>
        <table border="1" width="100%" cellpadding="0" cellspacing="0">
            <Component id="list"></Component>
        </table>
        <Component id="message"></Component>
        <div style="height:40px;"></div>
    </div>
    <div style="width:5px;background-color:navy;"></div>
    <div id="mainPanel" style="flex:1;padding:20px;overflow:auto;">
        <div id="lblSettings" style="cursor:pointer;">🔧 Input Settings</div>
        <div id="settingsPanel" style="padding-left:20px;">
            <div>
                <div>🔊 Audio</div>
                <div style="padding-left:20px;">
                    <div>
                        none
                        <button id="btnSetAudioNone">set</button>
                    </div>
                    <div>
                        microphone
                        <select id="mic_devices"></select>
                        <button id="btnSetMic">set</button>
                    </div>
                    <div>
                        audio file
                        <input id="fileAudio" type="file" multiple="true"/>
                        <button id="btnAddAudioFile">add</button>
                    </div>
                </div>
            </div>
            <div>
                <div>📺 Video</div>
                <div style="padding-left:20px;">
                    <div>
                        none
                        <button id="btnSetVideoNone">set</button>
                    </div>
                    <div>
                        screen
                        <button id="btnSetScreen">set</button>
                    </div>
                    <div>
                        camera
                        <select id="video_devices"></select>
                        <button id="btnSetCamera">set</button>
                    </div>
                    <div>
                        canvas
                        <button id="btnSetCanvas">set</button>
                    </div>
                </div>
            </div>
            <div style="height:40px;"></div>
        </div>
        
        <div>🎬 Stage</div>
        <div style="display:flex;">
            <button id="btnRecord">start recording</button>
            <button id="btnPlay">play</button>
            <button id="btnClearStage">clear</button>
            <div style="flex:1;"></div>
            <button id="btnDownloadMovie">download movie</button>
            <div style="flex:1;"></div>
            <button id="btnNext">change canvas</button>
        </div>
        
        <div style="padding-left:20px;">
            <div id="lblTracks" style="display:none;">
                <div>🛵 Tracks</div>
                <div style="display:flex;flex-wrap: wrap;">
                    <Component id="tracksView"></Component>
                </div>
            </div>
            <script>
                /*
                    Camera Hit Tracks
                    Movie Hit Tracks
                    Canvas Hit Tracks
                */
            </script>
        </div>
        <div style="display:flex;padding-top:10px;padding-bottom:10px;">
            <div id="chkMic" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">🔴 Mic</div>
            <div id="chkScreen" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">🔴 Screen</div>
            <div id="chkCamera" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">🔴 Camera</div>
            <div id="chkCanvas" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">🔴 Canvas</div>
        </div>
        <div id="mockHolder"></div>
        <div id="recordHolder">
            <Component id="mic_holder"></Component>
            <Component id="mic_holder2"></Component>
            <Component id="camera_holder"></Component>
            <canvas id="canvas_screen"></canvas>
        </div>
        
        <div id="playholder" style="display:none;">
            <div>🔵 Last Record</div>
            <video id="playscreen"></video>
            <Component id="playaudio"></Component>
        </div>
        <div>
            <button id="btnSend">save</button>
        </div>
        <div style="height:40px;"></div>
        <div>🐞 Debug</div>
        <div id="debug" style="font-family:'Cascadia Mono';font-size:10px;border:solid 2px #000; padding:20px;"></div>
        
    </div>
</div>
<div style="display:flex;background-color:navy;color:white;padding:10px;">
    <div style="flex:1;"></div><div>📋 Version 1.0 📅 July 2020</div>
</div>

<script>
if(this.fail) {
    main.el.style.display = "none";
    message.$.elementSetPacketAsync(`Hello World!`);
}

listPanel.el.style.height = (window.innerHeight-90) + "px";
mainPanel.el.style.height = (window.innerHeight-130) + "px";




var self = this;
this.app = {
    events : Class.create("WithEvents"),
    panel : {
        settings : {
            visible : true
        }
    },
    stream : null,
    tracks : [],
    recordType : "none",
    video : {
        mode : "none"
    },
    audio : {
        mode : "none"
    },
    hasAudioTracks : function () { for(var x = 0; x < this.tracks.length;x++) if(this.tracks[x].type == "audio") return true; return false; },
    hasVideoTracks : function () { for(var x = 0; x < this.tracks.length;x++) if(this.tracks[x].type == "video") return true; return false; }
};

btnClearStage.el.addEventListener("click",()=>{
    self.app.tracks.splice(0,self.app.tracks.length);
    self.app.events.emit("updateTracks");
});

lblSettings.el.addEventListener("click",()=>{
    if(self.app.panel.settings.visible) {
        settingsPanel.el.style.display = "none";
        self.app.panel.settings.visible = false;
    } else {
        settingsPanel.el.style.display = "";
        self.app.panel.settings.visible = true;

    }
})


// https://rawgit.com/Miguelao/demos/master/mediarecorder.html
//https://webrtc.github.io/samples/src/content/capture/canvas-record/
//https://webrtc.github.io/samples/src/content/capture/canvas-record/
function log(str) {
    debug.$.elementPushPacketAsync(`<div>${str}</div>`);
}
//canvas



canvas_screen.el.style.width = "640px";
canvas_screen.el.style.height = "480px";
canvas_screen.el.setAttribute("width",640);
canvas_screen.el.setAttribute("height",480);
canvas_screen.el.style.border = "solid 1px #000";

var ctx = canvas_screen.el.getContext("2d");
ctx.fillStyle = "#f00";
ctx.beginPath();
ctx.moveTo(0, 0);
ctx.lineTo(640, 0);
ctx.lineTo(640, 480);
ctx.closePath();
ctx.fill();
ctx.fillStyle = "#0f0";
ctx.beginPath();
ctx.moveTo(0, 480);
ctx.lineTo(640, 480);
ctx.lineTo(0, 0);
ctx.closePath();
ctx.fill();

var cstate = 0;
btnNext.el.addEventListener("click",()=>{
    switch(cstate%3) {
        case 0:
            ctx.fillStyle = "#00f";
            ctx.beginPath();
            ctx.moveTo(0, 0);
            ctx.lineTo(640, 0);
            ctx.lineTo(640, 480);
            ctx.closePath();
            ctx.fill();
            ctx.fillStyle = "#0f0";
            ctx.beginPath();
            ctx.moveTo(0, 480);
            ctx.lineTo(640, 480);
            ctx.lineTo(0, 0);
            ctx.closePath();
            ctx.fill();
            break;
        case 1:
            ctx.fillStyle = "#00f";
            ctx.beginPath();
            ctx.moveTo(0, 0);
            ctx.lineTo(640, 0);
            ctx.lineTo(640, 480);
            ctx.closePath();
            ctx.fill();
            ctx.fillStyle = "#f00";
            ctx.beginPath();
            ctx.moveTo(0, 480);
            ctx.lineTo(640, 480);
            ctx.lineTo(0, 0);
            ctx.closePath();
            ctx.fill();
            break;
        case 2:
            ctx.fillStyle = "#0f0";
            ctx.beginPath();
            ctx.moveTo(0, 0);
            ctx.lineTo(640, 0);
            ctx.lineTo(640, 480);
            ctx.closePath();
            ctx.fill();
            ctx.fillStyle = "#f00";
            ctx.beginPath();
            ctx.moveTo(0, 480);
            ctx.lineTo(640, 480);
            ctx.lineTo(0, 0);
            ctx.closePath();
            ctx.fill();
            break;
    }
    cstate++;
})
canvas_screen.el.style.display = "none";


var cstate1 = 0;
setInterval(()=>{ // like ping, to record something even if is a picture
    if(self.app.video.mode == "canvas" || self.app.video.mode == "play") {
        //console.log("OK");
        if(cstate1==0) {
            ctx.fillStyle = "#000";
            ctx.strokeStyle = "#00f";
            ctx.beginPath();
            ctx.moveTo(0, 479);
            ctx.lineTo(639, 479);
            ctx.closePath();
            ctx.stroke();   
            cstate1 = 1;
        } else if(cstate1==1) {
            ctx.fillStyle = "#001";
            ctx.strokeStyle = "#f00";
            ctx.beginPath();
            ctx.moveTo(0, 479);
            ctx.lineTo(479, 639);
            ctx.closePath();
            ctx.stroke();   
            cstate1 = 0;
        }
    }
},10);

// devices
//self.app.stream = stream = canvas_screen.el.captureStream(32); // frames per second
var stream = null;
self.app.stream = null;


let audioStream0 = null;

var stream0 = await navigator.mediaDevices.getUserMedia({video:true,audio:true});
stream0.getTracks().forEach(function(track) {
    track.stop();
});

navigator.mediaDevices.enumerateDevices()
  .then(gotDevices)
  .catch((error)=>{
    log('Error: '+ error.message);   
  });

async function gotDevices(deviceInfos) {
    //camera.el.srcObject = await navigator.mediaDevices.getUserMedia({video: true});
    //getStream();
    
    //camera.el.srcObject = await navigator.mediaDevices.getUserMedia({video: true});
    for (let i = 0; i !== deviceInfos.length; ++i) {
        const deviceInfo = deviceInfos[i];
        if (deviceInfo.kind === 'audioinput') {
            var schema = await mic_devices.$.elementPushPacketAsync(`
                <option id="opt">${ deviceInfo.label || 'mic' + (mic_devices.el.length+1) }</option>
            `);
            
            log(deviceInfo.kind + ": " + deviceInfo.label +
                " id = " + deviceInfo.deviceId);
            schema.el.opt.setAttribute("value",deviceInfo.deviceId);
            
        } else if (deviceInfo.kind === 'videoinput') {
            var schema = await video_devices.$.elementPushPacketAsync(`
                <option id="opt">${ deviceInfo.label || 'camera ' +
                (video_devices.el.length + 1) }</option>
            `)
            //alert(deviceInfo.deviceId);
            log(deviceInfo.kind + ": " + deviceInfo.label +
                " id = " + deviceInfo.deviceId);
            
            schema.el.opt.setAttribute("value",deviceInfo.deviceId);
    } else {
        //log('Found another kind of device: '+ deviceInfo);
        //console.log(deviceInfo);
    }
  }
}




btnSetMic.el.addEventListener("click",async ()=>{
    chkMic.el.style.display = "";

    self.app.audio.mode = "mic";
    const constraints = {
        audio : {
            deviceId : { exact : mic_devices.el.value }
        }
    };

    var schema = await mic_holder.$.elementSetPacketAsync(`
        <audio id="control"></audio>
    `);

    try {
        audioStream0 = schema.el.control.srcObject = await navigator.mediaDevices.getUserMedia(constraints);
    } catch(e) {
        audioStream0 = schema.el.control.src = window.URL.createObjectURL(await navigator.mediaDevices.getUserMedia(constraints));
    }
    schema.el.control.play();
    
});

btnAddAudioFile.el.addEventListener("click",async ()=>{
    function addTrack(file) {
        var reader = new FileReader();
        reader.onload = async function(e) {
            var arrayBuffer = this.result;
            var type = file.type.indexOf("audio") !=-1 ? "audio" : ( file.type.indexOf("video") != -1 ? "video" : null );
            if(type == null) { console.log("unkown file type : " + file.name); return; }
            var audio = new AudioContext();
            var bufferSource = await audio.decodeAudioData(arrayBuffer);
            var track = {
                type : type,
                data : {
                    mime : file.type,
                    name : file.name,
                    audio : audio,
                    buffer : bufferSource
                },
                events : []
            };
            fileAudio.el.value = "";
            self.app.tracks.push(track);
            console.log(track);
            self.app.events.emit("updateTracks");
        }
        reader.readAsArrayBuffer(file);
    }
    for(var x = 0; x < fileAudio.el.files.length;x++) {
        addTrack(fileAudio.el.files[x]);
    }
});



cameraDevice = null;

btnSetCamera.el.addEventListener("click",async ()=>{

    chkScreen.el.style.display = "none";
    chkCanvas.el.style.display = "none";
    chkCamera.el.style.display = "";
    
    if(self.app.video.mode == "play") {
        recordHolder.el.style.display = "";
        playscreen.el.style.display = "none";
    }
    self.app.video.mode = "camera";

    canvas_screen.el.style.display = "none";
    
    const constraints = {
        video: {
            deviceId: { exact : video_devices.el.value }
        }
    };
    var schema = await camera_holder.$.elementSetPacketAsync(`
        <video id="control"></video>
    `)
    schema.el.control.style.width = "100%";
    
    try {
      stream = schema.el.control.srcObject = await navigator.mediaDevices.getUserMedia(constraints);
    } catch (error) {
      stream = schema.el.control.src = window.URL.createObjectURL(await navigator.mediaDevices.getUserMedia(constraints));
    }
    schema.el.control.play();
    cameraDevice = schema.el.control;
});

btnSetCanvas.el.addEventListener("click",()=>{

    // CANVAS WILL NOT RECORD FIRST FRAME IF YOU DOWN CHANGE THE CONTENT OF CANVAS AT LEAST ONE TIME

    chkScreen.el.style.display = "none";
    chkCanvas.el.style.display = "";
    chkCamera.el.style.display = "none";


    if(cameraDevice) { // stop camera and screen
        console.log("CLEAR camera");
        cameraDevice.pause();
        stream.getTracks().forEach(function(track) {
          track.stop();
        });
        cameraDevice.style.display = "none";
        camera_holder.$.elementsClear();
    }

    if(self.app.video.mode == "play") {
        recordHolder.el.style.display = "";
        playscreen.el.style.display = "none";
    }
    self.app.video.mode = "canvas";
    canvas_screen.el.style.display = "";
    self.app.stream = stream = canvas_screen.el.captureStream(32);


    console.log(stream);

});

btnSetScreen.el.addEventListener("click",async ()=>{
    chkScreen.el.style.display = "";
    chkCanvas.el.style.display = "none";
    chkCamera.el.style.display = "none";

    canvas_screen.el.style.display = "none";
    

    if(cameraDevice) {
        cameraDevice.pause();
        stream.getTracks().forEach(function(track) {
          track.stop();
        });
        cameraDevice.style.display = "none";
        camera_holder.$.elementsClear();
    }

    if(self.app.video.mode == "play") {
        recordHolder.el.style.display = "";
        playscreen.el.style.display = "none";
    }
    self.app.video.mode = "desktop";

    
    const constraints = {
        video: {
            mediaSource: 'screen'
        }
    };
    const constraints2 = {
        video : true
    };
    
    //throw new Error("(audio only) not implemented by navigator, try mixing an recorded audio.");
    var stream2 = null;
    if (navigator.getDisplayMedia) {
        stream2 = await navigator.getDisplayMedia(constraints2);
    } else if (navigator.mediaDevices.getDisplayMedia) {
        stream2 = await navigator.mediaDevices.getDisplayMedia(constraints2);
    } else {
        stream2 = await navigator.mediaDevices.getUserMedia({video: {mediaSource: 'screen'}});
    }

    var schema = await camera_holder.$.elementSetPacketAsync(`
        <video id="control"></video>
    `)
    schema.el.control.style.width = "100%";
    
    try {
      stream = schema.el.control.srcObject = stream2;
    } catch (error) {
      stream = schema.el.control.src = window.URL.createObjectURL(stream2);
    }

    stream.getTracks().forEach((track)=>{
        track.onended = function(event) {
            log("end of screen capture");
            chkScreen.el.style.display = "none";
            stopRecording();
        }
    });

    schema.el.control.play();
    cameraDevice = schema.el.control;
});
btnSetVideoNone.el.addEventListener("click",()=>{

    chkScreen.el.style.display = "none";
    chkCanvas.el.style.display = "none";
    chkCamera.el.style.display = "none";


    if(cameraDevice) {
        cameraDevice.pause();
        stream.getTracks().forEach(function(track) {
          track.stop();
        });
        cameraDevice.style.display = "none";
        camera_holder.$.elementsClear();
    }

    if(self.app.video.mode == "play") {
        recordHolder.el.style.display = "";
        playscreen.el.style.display = "none";
    }

    self.app.video.mode = "none";
    camera_holder.$.elementsClear();
    playscreen.el.style.display = "none";  
    canvas_screen.el.style.display = "none";
});
btnSetAudioNone.el.addEventListener("click",()=>{
    chkMic.el.style.display = "none";
    self.app.audio.mode = "none";
    audioStream0.getTracks().forEach((track)=>{
        track.stop();
    })
});


let mediaRecorder;
let recordedBlobs = [];
let sourceBuffer;

const mediaSource = new MediaSource();
mediaSource.addEventListener('sourceopen', function handleSourceOpen(event) {
    log('MediaSource opened');
    sourceBuffer = mediaSource.addSourceBuffer('video/webm; codecs="vp8"');
    log('Source buffer: ', sourceBuffer);
}, false);

log('Started stream capture from canvas element: '+ stream);




function toggleRecording() {
    if (btnRecord.el.textContent === 'start recording') {
        startRecording();
    } else {
        stopRecording();
        btnRecord.el.textContent = 'start recording';
        btnPlay.el.disabled = false;
        btnDownloadMovie.el.disabled = false;
    }
}


function handleDataAvailable(event) {
    
    if (event.data && event.data.size > 0) {
        console.log(event.data);
        recordedBlobs.push(event.data);
    } else {
        //console.log( mediaRecorder.requestData() );
        //console.log(event);
    }
}

async function handlePause(event) {
    log('Recorder paused: ', event);
}
async function handleStop(event) {
    log('Recorder stopped: ', event);
    await self.app.audio.ctx.close();

    for(var x = 0; x < self.app.audio.recordTracks.length;x++) {
        console.log("removing tracks");
        stream.removeTrack(self.app.audio.recordTracks[x]);
    }

    if(self.app.video.mode == "none") {
        const superBuffer = new Blob(recordedBlobs, {type: 'audio/webm'});
        var url = (window.URL || window.webkitURL).createObjectURL(superBuffer);
        var schema = await playaudio.$.elementSetPacketAsync(`
            <audio id="audio" controls>
                <source src="`+url+`" type="audio/webm">
                Your browser does not support the audio tag.
            </audio>
        `);
        self.app.audio.control = schema.el.audio;
        self.app.events.off("hitTrack",self.app.events.hitTrack);
        delete self.app.events.hitTrack;
    } else {
        const superBuffer = new Blob(recordedBlobs, {type: 'video/webm'});
        playscreen.el.src = window.URL.createObjectURL(superBuffer);
        self.app.events.off("hitTrack",self.app.events.hitTrack);
    }
    
}




// The nested try blocks will be simplified when Chrome 47 moves to Stable
function startRecording() {

    if(self.app.video.mode == "none" && self.app.audio.mode == "none" && !self.app.hasAudioTracks()) {
        throw new Error("(you must select some input device)");
        return;
    }
    console.log("video mode",self.app.video.mode)
    console.log("audio mode",self.app.audio.mode)
    recordHolder.el.style.display = "";
    recordedBlobs = [];

    
    var audioCtx = new AudioContext();
    self.app.audio.ctx = audioCtx;
    self.app.audio.recordTracks = [];

    var audioMixer = audioCtx.createMediaStreamDestination();

    if( self.app.audio.mode == "mic" ) {
        var microphone = audioCtx.createMediaStreamSource(audioStream0);
        var microphoneGain = audioCtx.createGain();
        microphone.connect(microphoneGain);
        microphoneGain.gain.value = 0.5;
        microphoneGain.connect(audioMixer);
        microphone.connect(audioCtx.destination);
    }

    if(self.app.hasAudioTracks()) {
        self.app.events.hitTrack = (n)=>{
            if(n < self.app.tracks.length && self.app.tracks[n].type == "audio") {
                var playback = audioCtx.createBufferSource();
                var playbackGain = audioCtx.createGain();
                playback.buffer = self.app.tracks[n].data.buffer;
                playback.connect(playbackGain);
                playbackGain.gain.value = 0.5;
                playbackGain.connect(audioMixer);
                playbackGain.connect(audioCtx.destination);
                playback.start();
            }
            console.log("hit",self.app.tracks[n]);
        };
        self.app.events.on("hitTrack",self.app.events.hitTrack);

        // null signal to record empty audio space if mic is not activated
        var nullSignal = audioCtx.createOscillator();
        nullSignal.type = 'sine';
        nullSignal.frequency.value = 440;
        var nullSignalGain = audioCtx.createGain();
        nullSignalGain.gain.value = -100;
        nullSignalGain.connect(audioMixer);
    }

    // mixing audio and video
    if( ( self.app.audio.mode == "mic" || self.app.hasAudioTracks() ) && self.app.video.mode != "none") {
        console.log("MIXED IN AUDIO AND VIDEO");
        audioMixer.stream
            .getAudioTracks()
            .forEach((audioTrack) => {
                self.app.audio.recordTracks.push(audioTrack);
                console.log(audioTrack);
                stream.addTrack(audioTrack);
            });
    }
    
    if(self.app.video.mode != "none") {
        self.app.recordType = "video";
    } else {
        self.app.recordType = "audio";
    }

    var options = {};
    if(self.app.recordType == "video") {

        console.log("VIDEO RECORD TYPE");
        options.mimeType =  'video/webm';
        try {
            mediaRecorder = new MediaRecorder(stream, options);
        } catch (e0) {
            try {
                options.mimeType = 'video/webm,codecs=vp9';
                mediaRecorder = new MediaRecorder(stream, options);
            } catch (e1) {
                try {
                    options = 'video/vp8'; // Chrome 47
                    mediaRecorder = new MediaRecorder(stream, options);
                } catch (e2) {
                    log(`MediaRecorder is not supported by this browser.`);
                    log('Exception while creating MediaRecorder:'+ e2);
                    return;
                }
            }
        }
    } else {

        //stream = new MediaStream(stream.getAudioTracks());
        stream = audioMixer.stream;
        try {
            options.mimeType =  'audio/webm';
            mediaRecorder = new MediaRecorder(stream, options);
            
        } catch(e) {
            try {
                options.mimeType = 'audio/webm;codecs=opus';
                mediaRecorder = new MediaRecorder(stream, options);
                
            } catch(e1) {
                log(`Media Recorder is not supported by this browser.`);
                log('Exception while creating MediaRecorder:'+ e1);
                return;
            }
        }
    }

    log('Created MediaRecorder', mediaRecorder, 'with options', options);
    btnRecord.el.textContent = 'stop recording';
    btnPlay.el.disabled = true;
    btnDownloadMovie.el.disabled = true;
    mediaRecorder.onstop = handleStop;
    mediaRecorder.onpause = handlePause;
    mediaRecorder.ondataavailable = handleDataAvailable;
    mediaRecorder.onerror = function(error) {
        console.log(error.name);
        console.log(error);
    }
    mediaRecorder.start();
    try {
        
    } catch(e) {
        log("error on media recorder start");
        log(e.message);
    }

    
    log('MediaRecorder started' + mediaRecorder);
}

function stopRecording() {
    if(mediaRecorder.state != "inactive") { 
        mediaRecorder.stop();    
    } else { // user stopped sharing screen.
        self.app.video.mode = "none";
        chkScreen.el.style.display = "none";
    }
    log('Recorded Blobs: '+ recordedBlobs.length);
    playscreen.el.controls = true;
}
async function download() {
    var nblob = await makeNcpBlob(recordedBlobs);
    const url = window.URL.createObjectURL(nblob);
    const a = document.createElement('a');
    a.style.display = 'none';
    a.href = url;
    a.download = 'last_record.ncp';
    document.body.appendChild(a);
    a.click();
    setTimeout(() => {
        document.body.removeChild(a);
        window.URL.revokeObjectURL(url);
    }, 10000);
}

btnRecord.el.addEventListener("click",()=>{ toggleRecording(); });
btnPlay.el.addEventListener("click",()=>{ 

    playholder.el.style.display = "";
    recordHolder.el.style.display = "none";
    if(self.app.recordType == "audio") {
        playscreen.el.style.display = "none";
        self.app.audio.control.play();
        self.app.audio.mode = "play";
    } else if(self.app.recordType == "video") {
        playscreen.el.style.display = "";
        playaudio.$.elementsClear();
        playscreen.el.style.width = "100%";
        playscreen.el.play();  
        self.app.video.mode = "play";
    }
});
btnDownloadMovie.el.addEventListener("click",()=>{ download(); });

async function makeNcpBlob(blobs) {
    var blob,type;
    if(self.app.video.mode=="none") {
        blob = new Blob(recordedBlobs, {type: 'audio/webm'});
        type = "audio.webm";
    } else {
        blob = new Blob(recordedBlobs, {type: 'video/webm'});
        type = "video.webm";
    }
    var zip = new JSZip();
    zip.file("data.webm", blob);
    zip.file("spec.json", JSON.stringify({
        version : [0,0,1],
        type : type,
        main : "data.webm"
    }));
    return await zip.generateAsync({type:"blob"});
}

btnSend.el.addEventListener("click",async ()=>{
    var nblob = await makeNcpBlob(recordedBlobs);
    Import({url:"/send",method:"POST",type:Import.Binary,data : nblob })
    .done((data)=>{
        console.log(data);
        refresh_list();
    })
    .send();
});


self.app.events.on("updateTracks",()=>{
    // do not remove duplicate tracks cause it may be same track name for different folders
    tracksView.$.elementsClear();
    async function addTrack(n,track) {
        if(track.type == "audio") {
            var schema = await tracksView.$.elementPushPacketAsync(`
                <div style="display:flex;">
                    <div style="padding-left:5px;padding-right:5px;">🔊 ${(""+n).padStart(2,"0")}</div>
                    <div style="padding-left:5px;padding-right:5px;width:100px;overflow:hidden;white-space: nowrap;">${track.data.name}</div>
                    <div style="padding-left:5px;padding-right:5px;"><button id="btnHit">hit</button></div>
                </div>
            `);
            schema.el.btnHit.addEventListener("click",()=>{
                self.app.events.emit("hitTrack",[n]);
            });
        }
    }
    if(self.app.tracks.length>0) lblTracks.el.style.display = "";
    else lblTracks.el.style.display = "none";
    for(var x =0; x < self.app.tracks.length;x++) {
        addTrack(x,self.app.tracks[x]);
    }
});


async function addAsset(item) {
    var visible = false;
    var itemStruct = {
        init : false,
        data : item
    };
    var schema1 = await schema.$.list.elementUnshiftPacketAsync(`
        <tr style="cursor:pointer;">
            <td id="item">📼 ${item.id}</td>
            <td>🔽<a href="/messages/user1/${item.file}.ncp" download>download</a></td>
            <td id="addAsTrack">📌 add as track</td>
        </tr>
        <Component id="holder"></Component>
    `);
    itemStruct.schema1 = schema1;
    schema1.el.item.addEventListener("click",async ()=>{
        if(!visible) {
            if(!itemStruct.init) {
                itemStruct.init = true;
                var data = await fetch(`/messages/user1/${item.file}.ncp`);
                var blob = await data.blob();
                var schema2 = await schema1.$.holder.elementPushPacketAsync(`
                    <tr id="view">
                        <td colspan="4" align="center">
                            <div>📅 ${item.date}</div>
                            <Component id="ncp" src="ncp.super" data={{this.src}}></Component>
                            <div id="sc"></div>
                        </td>
                    </tr>
                `,{context:{src:blob}});
                itemStruct.schema2 = schema2;
                schema2.el.sc.scrollIntoView({block:"center"});
                schema2.exports.ncp.control.el.play();
                if( schema2.exports.ncp.spec.type == "audio.webm" ) {

                } else if(schema2.exports.ncp.spec.type == "video.webm") { // video tag, expecting bad margin, 100% width is custom
                    schema2.exports.ncp.control.el.style.width = "100%";
                    schema2.exports.ncp.control.el.style.marginBottom = "-7px";
                }
            } else {
                itemStruct.schema2.el.view.style.display = "";
                itemStruct.schema2.el.sc.scrollIntoView({block:"center"});
                itemStruct.schema2.exports.ncp.control.el.play();
            }
            
            visible = true;
        } else {
            itemStruct.schema2.el.view.style.display = "none";
            visible = false;
        }
    });
    schema1.el.addAsTrack.addEventListener("click",async ()=>{
        console.log("addAsTrack");
        var data = await fetch(`/messages/user1/${item.file}.ncp`);
        var blob = await data.blob();
        async function load() {
            this.zip = await JSZip.loadAsync(this.props.data);
            var result = await this.zip.file("spec.json").async("string");
            this.spec = JSON.parse(result);
            // bound to 0.0.1
            if( this.spec.type == "audio.webm" ) {
                // change by this point compared to control
                var arrayBuffer = await this.zip.file("data.webm").async("arraybuffer"); 
                var audio = new AudioContext();
                var bufferSource = await audio.decodeAudioData(arrayBuffer);
                var track = {
                    type : "audio",
                    data : {
                        mime : "application/ncp",
                        name : item.file + ".ncp",
                        audio : audio,
                        buffer : bufferSource
                    },
                    events : []
                };
                self.app.tracks.push(track);
                self.app.events.emit("updateTracks");
                console.log(track);
            } else if(this.spec.type == "video.webm") {
                throw new Error("video not implemented");
            }
            // end bound
        }
        load.apply({props:{data:blob}}); // to reuse this.zip same as ncp.super
    });
}
function refresh_list() {
    Import({url:"/list",method:"GET"})
    .done((data)=>{
        //alert(data);
        var json = JSON.parse(data);
        if(json.result) {
            schema.$.list.elementsClear();
            for(var x = 0; x < json.data.length;x++) {
                addAsset(json.data[x]);
            }
        }
    })
    .send();
}
refresh_list();

</script>
