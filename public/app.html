<script>
    this.fail = false;
    var self = this;
    try {
        /*
        var a = await fetch("/ping",{method:"POST"});
        if(a.status==404) {
            this.fail = true;
            self.props.fail();
        }
        */
    } catch(e) {
        this.fail = true;
        self.props.fail();
    }

    this.refresh_list = new Promise((resolve,reject)=>{
        Import({url:"/list",method:"GET"})
        .done((data)=>{
            //alert(data);
            var json = JSON.parse(data);
            resolve(json);
            
        })
        .send();
    });

</script>
<style>
    body {
        margin:0px;
    }
</style>
<div style="display:flex;background-color:navy;color:white;padding:10px;">
    <div>üßä NumberCooler Recorder Premium</div>
</div>
<div id="main" style="display:flex;padding:0px;border-left:solid 10px navy;border-right:solid 10px navy;">
    <div id="listPanel" style="flex:0.6;overflow:auto;">
        <div id="listPanelMock"></div>
        <table border="1" width="100%" cellpadding="0" cellspacing="0">
            <Component id="list"></Component>
        </table>
        <Component id="message"></Component>
        <div style="height:40px;"></div>
    </div>
    <div style="width:5px;background-color:navy;"></div>
    <div id="mainPanel" style="flex:1;padding:20px;overflow:auto;">
        <div id="lblSettings" style="cursor:pointer;">üîß Input Settings</div>
        <div id="settingsPanel" style="padding-left:20px;">
            <div>
                <div>üîä Audio</div>
                <div style="padding-left:20px;">
                    <div>
                        none
                        <button id="btnSetAudioNone">set</button>
                    </div>
                    <div>
                        microphone
                        <select id="mic_devices"></select>
                        <button id="btnSetMic">set</button>
                    </div>
                    <div>
                        audio file
                        <input id="fileAudio" type="file" multiple="true"/>
                        <button id="btnAddAudioFile">add</button>
                    </div>
                </div>
            </div>
            <div>
                <div>üì∫ Video</div>
                <div style="padding-left:20px;">
                    <div>Resolution</div>
                    <div style="padding-left:20px;">
                        <div style="display:flex;">
                            <div style="width:150px;border-right:solid 1px #000;padding-right:10px;">
                                <div style="display:flex;">
                                    <div style="flex:1;">width</div><div><input id="screenWidth" type="text" value="1920" style="width:50px;"/></div>
                                </div>
                                <div style="display:flex;">
                                    <div style="flex:1;">height</div><div><input id="screenHeight" type="text" value="1080" style="width:50px;"/></div>
                                </div>
                            </div>
                            <div style="font-weight:bold;font-size:10px;padding-left:10px;">
                                <div>(4:3)</div>
                                <div style="display:flex;padding-left:10px;">
                                    <div id="btnResQVGA" style="margin-right:10px;">QVGA</div>
                                    <div id="btnResVGA" style="margin-right:10px;">VGA</div>
                                    <div id="btnResSVGA" style="margin-right:10px;">SVGA</div>
                                    <div id="btnResXGA" style="margin-right:10px;">XGA</div>
                                </div>
                                <div>(16:9)</div>
                                <div style="display:flex;padding-left:10px;">
                                    <div id="btnResFWVGA" style="margin-right:10px;">FWVGA</div>
                                    <div id="btnResHD720" style="margin-right:10px;">HD 720</div>
                                    <div id="btnResHD1080" style="margin-right:10px;">HD 1080</div>
                                </div>
                                <div>(custom)</div>
                                <div style="display:flex;padding-left:10px;">
                                    <div id="btnResTwitter1" style="margin-right:10px;">Twitter Post</div>
                                    <div id="btnResFacebook1" style="margin-right:10px;">Facebook Post</div>
                                </div>

                            </div>
                        </div>
                    </div>
                
                </div>
                <div style="padding-left:20px;">
                    <div>
                        none
                        <button id="btnSetVideoNone">set</button>
                    </div>
                    <div>
                        screen
                        <button id="btnAddScreen">add</button>
                    </div>
                    <div>
                        camera
                        <select id="video_devices"></select>
                        <button id="btnAddCamera">add</button>
                    </div>
                    <div>
                        image file
                        <input id="fileImage" type="file" multiple="true"/>
                        <button id="btnAddImageFile">add</button>
                    </div>

                </div>
            </div>
            <div style="height:40px;"></div>
        </div>
        
        <div>üé¨ Stage</div>
        <div style="display:flex;">
            <button id="btnRecord">start recording</button>
            <button id="btnPlay">play</button>
            <button id="btnClearStage">clear</button>
            <div style="flex:1;"></div>
            <button id="btnDownloadMovie">download movie</button>
            <div style="flex:1;"></div>
            <button id="btnNext">change canvas</button>
        </div>
        
        <div style="padding-left:20px;">
            <div id="lblTracks" style="display:none;">
                <div>üõµ Tracks</div>
                <div style="display:flex;flex-wrap: wrap;">
                    <Component id="tracksView"></Component>
                </div>
            </div>
            <script>
                /*
                    Camera Hit Tracks
                    Movie Hit Tracks
                    Canvas Hit Tracks
                */
            </script>
        </div>
        <div style="display:flex;padding-top:10px;padding-bottom:10px;">
            <div id="chkMic" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">üî¥ Mic</div>
            <div id="chkScreen" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">üî¥ Screen</div>
            <div id="chkCamera" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">üî¥ Camera</div>
            <div id="chkCanvas" style="display:none;padding:5px;background-color:gainsboro;border-radius:20px;padding-left:15px;padding-right:15px;margin-right:10px;">üî¥ Canvas</div>
        </div>
        <div id="mockHolder"></div>
        <div id="recordHolder">
            
            <Component id="mic_holder"></Component>
            <Component id="mic_holder2"></Component>
            <Component id="camera_holder"></Component>
            <canvas id="canvas_screen"></canvas>
        </div>
        
        <div id="playholder" style="display:none;">
            <div>üîµ Last Record</div>
            <video id="playscreen"></video>
            <Component id="playaudio"></Component>
        </div>
        <div>
            <button id="btnSend">save</button>
        </div>
        <div style="height:40px;"></div>
        <div>üêû Debug</div>
        <div id="debug" style="font-family:'Cascadia Mono';font-size:10px;border:solid 2px #000; padding:20px;"></div>
        
    </div>
</div>
<div style="display:flex;background-color:navy;color:white;padding:10px;">
    <div style="flex:1;"></div><div>üìã Version 1.0 üìÖ July 2020</div>
</div>

<script>
if(this.fail) {
    main.el.style.display = "none";
    message.$.elementSetPacketAsync(`Hello World!`);
}



btnResQVGA.el.addEventListener("click",()=>{
    screenWidth.el.value = "320";
    screenHeight.el.value = "240";
});
btnResVGA.el.addEventListener("click",()=>{
    screenWidth.el.value = "640";
    screenHeight.el.value = "480";
});
btnResSVGA.el.addEventListener("click",()=>{
    screenWidth.el.value = "800";
    screenHeight.el.value = "600";
});
btnResXGA.el.addEventListener("click",()=>{
    screenWidth.el.value = "1024";
    screenHeight.el.value = "768";
});
btnResFWVGA.el.addEventListener("click",()=>{
    screenWidth.el.value = "854";
    screenHeight.el.value = "480";
});
btnResHD720.el.addEventListener("click",()=>{
    screenWidth.el.value = "1280";
    screenHeight.el.value = "720";
});
btnResHD1080.el.addEventListener("click",()=>{
    screenWidth.el.value = "1920";
    screenHeight.el.value = "1080";
});
btnResTwitter1.el.addEventListener("click",()=>{
    screenWidth.el.value = "440";
    screenHeight.el.value = "220";
});
btnResFacebook1.el.addEventListener("click",()=>{
    screenWidth.el.value = "500";
    screenHeight.el.value = "282";
});


listPanel.el.style.height = (window.innerHeight-90) + "px";
mainPanel.el.style.height = (window.innerHeight-130) + "px";




var self = this;
this.app = {
    events : Class.create("WithEvents"),
    panel : {
        settings : {
            visible : true
        }
    },
    stream : null,
    tracks : [],
    recordType : "none",
    recordState : "stopped",
    video : {
        mode : "none",
    },
    audio : {
        mode : "none"
    },
    hasAudioTracks : function () { for(var x = 0; x < this.tracks.length;x++) if(this.tracks[x].type == "audio") return true; return false; },
    hasVideoTracks : function () { for(var x = 0; x < this.tracks.length;x++) if(this.tracks[x].type == "video") return true; return false; }
};


async function refresh_list(update) {
    var data = null;
    if(update) {
        data = await new Promise((resolve,reject)=>{
            Import({url:"/list",method:"GET"})
            .done((data)=>{
                //alert(data);
                var json = JSON.parse(data);
                resolve(json);
                
            })
            .send();
        });
    } else {
        data = await self.refresh_list;
    }
    console.log("LIST1",data);
    if(data?.result) {
        schema.$.list.elementsClear();
        for(var x = 0; x < data.data.length;x++) {
            addAsset(data.data[x]);
        }
    }    
}
refresh_list();

btnClearStage.el.addEventListener("click",()=>{
    self.app.tracks.splice(0,self.app.tracks.length);
    self.app.events.emit("updateTracks");
});

lblSettings.el.addEventListener("click",()=>{
    if(self.app.panel.settings.visible) {
        settingsPanel.el.style.display = "none";
        self.app.panel.settings.visible = false;
    } else {
        settingsPanel.el.style.display = "";
        self.app.panel.settings.visible = true;

    }
})


// https://rawgit.com/Miguelao/demos/master/mediarecorder.html
//https://webrtc.github.io/samples/src/content/capture/canvas-record/
//https://webrtc.github.io/samples/src/content/capture/canvas-record/
function log(str) {
    debug.$.elementPushPacketAsync(`<div>${str}</div>`);
}
//canvas



canvas_screen.el.style.width = "640px";
canvas_screen.el.style.height = "480px";
canvas_screen.el.setAttribute("width",640);
canvas_screen.el.setAttribute("height",480);
canvas_screen.el.style.border = "solid 1px #000";

var ctx = canvas_screen.el.getContext("2d");
ctx.fillStyle = "#f00";
ctx.beginPath();
ctx.moveTo(0, 0);
ctx.lineTo(640, 0);
ctx.lineTo(640, 480);
ctx.closePath();
ctx.fill();
ctx.fillStyle = "#0f0";
ctx.beginPath();
ctx.moveTo(0, 480);
ctx.lineTo(640, 480);
ctx.lineTo(0, 0);
ctx.closePath();
ctx.fill();

var cstate = 0;
btnNext.el.addEventListener("click",()=>{
    switch(cstate%3) {
        case 0:
            ctx.fillStyle = "#00f";
            ctx.beginPath();
            ctx.moveTo(0, 0);
            ctx.lineTo(640, 0);
            ctx.lineTo(640, 480);
            ctx.closePath();
            ctx.fill();
            ctx.fillStyle = "#0f0";
            ctx.beginPath();
            ctx.moveTo(0, 480);
            ctx.lineTo(640, 480);
            ctx.lineTo(0, 0);
            ctx.closePath();
            ctx.fill();
            break;
        case 1:
            ctx.fillStyle = "#00f";
            ctx.beginPath();
            ctx.moveTo(0, 0);
            ctx.lineTo(640, 0);
            ctx.lineTo(640, 480);
            ctx.closePath();
            ctx.fill();
            ctx.fillStyle = "#f00";
            ctx.beginPath();
            ctx.moveTo(0, 480);
            ctx.lineTo(640, 480);
            ctx.lineTo(0, 0);
            ctx.closePath();
            ctx.fill();
            break;
        case 2:
            ctx.fillStyle = "#0f0";
            ctx.beginPath();
            ctx.moveTo(0, 0);
            ctx.lineTo(640, 0);
            ctx.lineTo(640, 480);
            ctx.closePath();
            ctx.fill();
            ctx.fillStyle = "#f00";
            ctx.beginPath();
            ctx.moveTo(0, 480);
            ctx.lineTo(640, 480);
            ctx.lineTo(0, 0);
            ctx.closePath();
            ctx.fill();
            break;
    }
    cstate++;
})
canvas_screen.el.style.display = "none";


var cstate1 = 0;
setInterval(()=>{ // like ping, to record something even if is a picture
    if(self.app.video.mode == "canvas" || self.app.video.mode == "play") {
        //console.log("OK");
        if(cstate1==0) {
            ctx.fillStyle = "#000";
            ctx.strokeStyle = "#00f";
            ctx.beginPath();
            ctx.moveTo(0, 479);
            ctx.lineTo(639, 479);
            ctx.closePath();
            ctx.stroke();   
            cstate1 = 1;
        } else if(cstate1==1) {
            ctx.fillStyle = "#001";
            ctx.strokeStyle = "#f00";
            ctx.beginPath();
            ctx.moveTo(0, 479);
            ctx.lineTo(479, 639);
            ctx.closePath();
            ctx.stroke();   
            cstate1 = 0;
        }
    }
},10);

// devices
//self.app.stream = stream = canvas_screen.el.captureStream(32); // frames per second
var stream = null;
self.app.stream = null;


let audioStream0 = null;

var stream0 = await navigator.mediaDevices.getUserMedia({video:true,audio:true});
stream0.getTracks().forEach(function(track) {
    track.stop();
});

navigator.mediaDevices.enumerateDevices()
  .then(gotDevices)
  .catch((error)=>{
    log('Error: '+ error.message);   
  });

async function gotDevices(deviceInfos) {
    //camera.el.srcObject = await navigator.mediaDevices.getUserMedia({video: true});
    //getStream();
    
    //camera.el.srcObject = await navigator.mediaDevices.getUserMedia({video: true});
    for (let i = 0; i !== deviceInfos.length; ++i) {
        const deviceInfo = deviceInfos[i];
        if (deviceInfo.kind === 'audioinput') {
            var schema = await mic_devices.$.elementPushPacketAsync(`
                <option id="opt">${ deviceInfo.label || 'mic' + (mic_devices.el.length+1) }</option>
            `);
            
            log(deviceInfo.kind + ": " + deviceInfo.label +
                " id = " + deviceInfo.deviceId);
            schema.el.opt.setAttribute("value",deviceInfo.deviceId);
            
        } else if (deviceInfo.kind === 'videoinput') {
            var schema = await video_devices.$.elementPushPacketAsync(`
                <option id="opt">${ deviceInfo.label || 'camera ' +
                (video_devices.el.length + 1) }</option>
            `)
            //alert(deviceInfo.deviceId);
            log(deviceInfo.kind + ": " + deviceInfo.label +
                " id = " + deviceInfo.deviceId);
            
            schema.el.opt.setAttribute("value",deviceInfo.deviceId);
    } else {
        //log('Found another kind of device: '+ deviceInfo);
        //console.log(deviceInfo);
    }
  }
}




btnSetMic.el.addEventListener("click",async ()=>{
    chkMic.el.style.display = "";

    self.app.audio.mode = "mic";
    const constraints = {
        audio : {
            deviceId : { exact : mic_devices.el.value }
        }
    };

    var schema = await mic_holder.$.elementSetPacketAsync(`
        <audio id="control"></audio>
    `);

    try {
        audioStream0 = schema.el.control.srcObject = await navigator.mediaDevices.getUserMedia(constraints);
    } catch(e) {
        audioStream0 = schema.el.control.src = window.URL.createObjectURL(await navigator.mediaDevices.getUserMedia(constraints));
    }
    schema.el.control.play();
    
});

btnAddAudioFile.el.addEventListener("click",async ()=>{
    function addTrack(file) {
        var reader = new FileReader();
        reader.onload = async function(e) {
            var arrayBuffer = this.result;
            var type = file.type.indexOf("audio/") !=-1 ? "audio" : null;
            if(type == null) { console.log("not an audio file : " + file.name); return; }
            var audio = new AudioContext();
            var bufferSource = await audio.decodeAudioData(arrayBuffer);
            var track = {
                type : type,
                data : {
                    mime : file.type,
                    name : file.name,
                    audio : audio,
                    buffer : bufferSource
                },
                events : []
            };
            fileAudio.el.value = "";
            self.app.tracks.push(track);
            console.log(track);
            self.app.events.emit("updateTracks");
        }
        reader.readAsArrayBuffer(file);
    }
    for(var x = 0; x < fileAudio.el.files.length;x++) {
        addTrack(fileAudio.el.files[x]);
    }
});
btnAddImageFile.el.addEventListener("click",async ()=>{
    function addTrack(file) {
        var reader = new FileReader();
        reader.onload = async function(e) {
            var arrayBuffer = this.result;
            var type = file.type.indexOf("image/") !=-1 ? "image" : null;
            if(type == null) { console.log("not an image file : " + file.name); return; }

            var img = new Image();
            var blob =  new Blob([arrayBuffer]);
            img.src = window.URL.createObjectURL(blob);
            var track = {
                type : "video",
                data : {
                    mime : file.type,
                    name : file.name,
                    type : "image",
                    blob,
                    el : img
                },
                events : []
            };
            fileImage.el.value = "";
            self.app.tracks.push(track);
            console.log(track);
            self.app.events.emit("updateTracks");
        }
        reader.readAsArrayBuffer(file);
    }
    for(var x = 0; x < fileImage.el.files.length;x++) {
        addTrack(fileImage.el.files[x]);
    }

});


cameraDevice = null;
/*
btnSetCamera.el.addEventListener("click",async ()=>{

    chkScreen.el.style.display = "none";
    chkCanvas.el.style.display = "none";
    chkCamera.el.style.display = "";
    
    if(self.app.video.mode == "play") {
        recordHolder.el.style.display = "";
        playscreen.el.style.display = "none";
    }
    self.app.video.mode = "camera";

    canvas_screen.el.style.display = "none";
    
    cameraDevice = schema.el.control;
});
*/
var cameraNb = 0;
btnAddCamera.el.addEventListener("click",async ()=>{

    const constraints = {
        video: {
            deviceId: { exact : video_devices.el.value }
        }
    };
    var videoel = document.createElement("video");
    var stream = null;
    try {
        stream = videoel.srcObject = await navigator.mediaDevices.getUserMedia(constraints);
    } catch (error) {
        stream = videoel.src = window.URL.createObjectURL(await navigator.mediaDevices.getUserMedia(constraints));
    }
    document.body.appendChild(videoel);
    videoel.style.display = "none";
    videoel.play();
    var track = {
        type : "video",
        data : {
            name : "camera" + cameraNb,
            type : "camera",
            stream : stream,
            el : videoel
        },
        events : []
    };
    cameraNb++;
    self.app.tracks.push(track);
    console.log(track);
    self.app.events.emit("updateTracks");
});

/*
btnSetScreen.el.addEventListener("click",async ()=>{
    chkScreen.el.style.display = "";
    chkCanvas.el.style.display = "none";
    chkCamera.el.style.display = "none";

    canvas_screen.el.style.display = "none";
    

    if(cameraDevice) {
        cameraDevice.pause();
        stream.getTracks().forEach(function(track) {
          track.stop();
        });
        cameraDevice.style.display = "none";
        camera_holder.$.elementsClear();
    }

    if(self.app.video.mode == "play") {
        recordHolder.el.style.display = "";
        playscreen.el.style.display = "none";
    }
    self.app.video.mode = "desktop";

    stream.getTracks().forEach((track)=>{
        track.onended = function(event) {
            log("end of screen capture");
            chkScreen.el.style.display = "none";
            stopRecording();
        }
    });

    schema.el.control.play();
    cameraDevice = schema.el.control;
});
*/
var screenNb = 0;
btnAddScreen.el.addEventListener("click",async ()=>{
    const constraints = { video : true };
    var videoel = document.createElement("video");
    var stream = null;
    if (navigator.getDisplayMedia) {
        stream = videoel.srcObject = await navigator.getDisplayMedia(constraints);
    } else if (navigator.mediaDevices.getDisplayMedia) {
        stream = videoel.srcObject = await navigator.mediaDevices.getDisplayMedia(constraints);
    } else {
        stream = videoel.srcObject = await navigator.mediaDevices.getUserMedia({video: {mediaSource: 'screen'}});
    }
    videoel.play();

    var track = {
        type : "video",
        data : {
            name : "screen"+screenNb,
            type : "screen",
            stream : stream,
            el : videoel
        },
        events : []
    };
    screenNb++;
    self.app.tracks.push(track);
    console.log(track);
    self.app.events.emit("updateTracks");

});

btnSetVideoNone.el.addEventListener("click",()=>{

    chkScreen.el.style.display = "none";
    chkCanvas.el.style.display = "none";
    chkCamera.el.style.display = "none";


    if(cameraDevice) {
        cameraDevice.pause();
        stream.getTracks().forEach(function(track) {
          track.stop();
        });
        cameraDevice.style.display = "none";
        camera_holder.$.elementsClear();
    }

    if(self.app.video.mode == "play") {
        recordHolder.el.style.display = "";
        playscreen.el.style.display = "none";
    }

    self.app.video.mode = "none";
    camera_holder.$.elementsClear();
    playscreen.el.style.display = "none";  
    canvas_screen.el.style.display = "none";
});
btnSetAudioNone.el.addEventListener("click",()=>{
    chkMic.el.style.display = "none";
    self.app.audio.mode = "none";
    if(audioStream0) audioStream0.getTracks().forEach((track)=>{
        track.stop();
    })
});


let mediaRecorder;
let recordedBlobs = [];
let sourceBuffer;

const mediaSource = new MediaSource();
mediaSource.addEventListener('sourceopen', function handleSourceOpen(event) {
    log('MediaSource opened');
    sourceBuffer = mediaSource.addSourceBuffer('video/webm; codecs="vp8"');
    log('Source buffer: ', sourceBuffer);
}, false);

log('Started stream capture from canvas element: '+ stream);




function toggleRecording() {
    if (btnRecord.el.textContent === 'start recording') {
        startRecording();
    } else {
        stopRecording();
        btnRecord.el.textContent = 'start recording';
        btnPlay.el.disabled = false;
        btnDownloadMovie.el.disabled = false;
    }
}


function handleDataAvailable(event) {
    
    if (event.data && event.data.size > 0) {
        console.log("DATA",event.data);
        recordedBlobs.push(event.data);
    } else {
        //console.log( mediaRecorder.requestData() );
        //console.log(event);
    }
}

async function handlePause(event) {
    log('Recorder paused: ', event);
}
async function handleStop(event) {
    log('Recorder stopped: ', event);
    await self.app.audio.ctx.close();

    for(var x = 0; x < self.app.audio.recordTracks.length;x++) {
        console.log("removing tracks");
        stream.removeTrack(self.app.audio.recordTracks[x]);
    }
    if(self.app.video.mode == "none") {
        const superBuffer = new Blob(recordedBlobs, {type: 'audio/webm'});
        var url = (window.URL || window.webkitURL).createObjectURL(superBuffer);
        var schema = await playaudio.$.elementSetPacketAsync(`
            <audio id="audio" controls>
                <source src="`+url+`" type="audio/webm">
                Your browser does not support the audio tag.
            </audio>
        `);
        self.app.audio.control = schema.el.audio;
        
        delete self.app.events.hitTrack;
    } else {
        const superBuffer = new Blob(recordedBlobs, {type: 'video/webm'});
        playscreen.el.src = window.URL.createObjectURL(superBuffer);
        
    }
    
    self.app.recordState = "stopped";
}




// The nested try blocks will be simplified when Chrome 47 moves to Stable
function startRecording() {

    if(self.app.video.mode == "none" && self.app.audio.mode == "none" && !self.app.hasAudioTracks()) {
        throw new Error("(you must select some input device)");
        return;
    }
    console.log("video mode",self.app.video.mode)
    console.log("audio mode",self.app.audio.mode)
    recordHolder.el.style.display = "";
    recordedBlobs = [];
    if(self.app.events.hitTrack)
        self.app.events.off("hitTrack",self.app.events.hitTrack);

    var audioCtx = new AudioContext();
    self.app.audio.ctx = audioCtx;
    self.app.audio.recordTracks = [];

    var audioMixer = audioCtx.createMediaStreamDestination();

    if( self.app.audio.mode == "mic" ) {
        var microphone = audioCtx.createMediaStreamSource(audioStream0);
        var microphoneGain = audioCtx.createGain();
        microphone.connect(microphoneGain);
        microphoneGain.gain.value = 0.5;
        microphoneGain.connect(audioMixer);
        microphone.connect(audioCtx.destination);

        // stop audio Mixer on audio none, or audio track clear.
    }

    if(self.app.hasAudioTracks()) {
        self.app.events.hitTrack = (n)=>{
            if(n < self.app.tracks.length && self.app.tracks[n].type == "audio") {
                var playback = audioCtx.createBufferSource();
                var playbackGain = audioCtx.createGain();
                playback.buffer = self.app.tracks[n].data.buffer;
                playback.connect(playbackGain);
                playbackGain.gain.value = 0.5;
                playbackGain.connect(audioMixer);
                playbackGain.connect(audioCtx.destination);
                playback.start();
            }
            console.log("hit",self.app.tracks[n]);
        };
        self.app.events.on("hitTrack",self.app.events.hitTrack);

        // null signal to record empty audio space if mic is not activated
        var nullSignal = audioCtx.createOscillator();
        nullSignal.type = 'sine';
        nullSignal.frequency.value = 440;
        var nullSignalGain = audioCtx.createGain();
        nullSignalGain.gain.value = -100;
        nullSignalGain.connect(audioMixer);
    }

    // mixing audio and video
    if( ( self.app.audio.mode == "mic" || self.app.hasAudioTracks() ) && self.app.video.mode != "none") {
        console.log("MIXED IN AUDIO AND VIDEO");
        audioMixer.stream
            .getAudioTracks()
            .forEach((audioTrack) => {
                self.app.audio.recordTracks.push(audioTrack);
                console.log(audioTrack);
                stream.addTrack(audioTrack);
            });
        
    }
    
    if(self.app.video.mode != "none") {
        self.app.recordType = "video";
    } else {
        self.app.recordType = "audio";
    }

    var options = {};
    if(self.app.recordType == "video") {

        console.log("VIDEO RECORD TYPE");
        options.mimeType =  'video/webm';
        try {
            mediaRecorder = new MediaRecorder(stream, options);
        } catch (e0) {
            try {
                options.mimeType = 'video/webm,codecs=vp9';
                mediaRecorder = new MediaRecorder(stream, options);
            } catch (e1) {
                try {
                    options = 'video/vp8'; // Chrome 47
                    mediaRecorder = new MediaRecorder(stream, options);
                } catch (e2) {
                    log(`MediaRecorder is not supported by this browser.`);
                    log('Exception while creating MediaRecorder:'+ e2);
                    return;
                }
            }
        }
    } else {

        //stream = new MediaStream(stream.getAudioTracks());
        stream = audioMixer.stream;
        try {
            options.mimeType =  'audio/webm';
            mediaRecorder = new MediaRecorder(stream, options);
            
        } catch(e) {
            try {
                options.mimeType = 'audio/webm;codecs=opus';
                mediaRecorder = new MediaRecorder(stream, options);
                
            } catch(e1) {
                log(`Media Recorder is not supported by this browser.`);
                log('Exception while creating MediaRecorder:'+ e1);
                return;
            }
        }
    }

    log('Created MediaRecorder', mediaRecorder, 'with options', options);
    btnRecord.el.textContent = 'stop recording';
    btnPlay.el.disabled = true;
    btnDownloadMovie.el.disabled = true;
    mediaRecorder.onstop = handleStop;
    mediaRecorder.onpause = handlePause;
    mediaRecorder.ondataavailable = handleDataAvailable;
    mediaRecorder.onerror = function(error) {
        console.log(error.name);
        console.log(error);
    }
    self.app.recordState = "recording";
    mediaRecorder.start(1000/30);
    try {

    } catch(e) {
        log("error on media recorder start");
        log(e.message);
    }

    
    log('MediaRecorder started' + mediaRecorder);
}

function stopRecording() {
    if(mediaRecorder.state != "inactive") { 
        mediaRecorder.stop();    
    } else { // user stopped sharing screen.
        self.app.video.mode = "none";
        chkScreen.el.style.display = "none";
    }
    log('Recorded Blobs: '+ recordedBlobs.length);
    playscreen.el.controls = true;
}
async function download() {
    var nblob = await makeNcpBlob(recordedBlobs);
    const url = window.URL.createObjectURL(nblob);
    const a = document.createElement('a');
    a.style.display = 'none';
    a.href = url;
    a.download = 'last_record.ncp';
    document.body.appendChild(a);
    a.click();
    setTimeout(() => {
        document.body.removeChild(a);
        window.URL.revokeObjectURL(url);
    }, 10000);
}

btnRecord.el.addEventListener("click",()=>{ toggleRecording(); });
btnPlay.el.addEventListener("click",()=>{ 

    playholder.el.style.display = "";
    recordHolder.el.style.display = "none";
    if(self.app.recordType == "audio") {
        playscreen.el.style.display = "none";
        self.app.audio.control.play();
        self.app.audio.mode = "play";
    } else if(self.app.recordType == "video") {
        playscreen.el.style.display = "";
        playaudio.$.elementsClear();
        playscreen.el.style.width = "100%";
        playscreen.el.play();  
        self.app.video.mode = "play";
    }
});
btnDownloadMovie.el.addEventListener("click",()=>{ download(); });

async function makeNcpBlob(blobs) {
    var blob,type;
    if(self.app.video.mode=="none") {
        blob = new Blob(recordedBlobs, {type: 'audio/webm'});
        type = "audio.webm";
    } else {
        blob = new Blob(recordedBlobs, {type: 'video/webm'});
        type = "video.webm";
    }

    var config_str = JSON.stringify({
        version : [0,0,2],
        type : type,
        main : "webm"
    });
    var config_ab = Binary.str2utf8ab(config_str);
    var webm_ab = await blob.arrayBuffer()
    var ncp_blob = new Blob( 
        new BinaryWriter().u32(config_ab.byteLength).data.concat([config_ab]) 
            .concat(
                new BinaryWriter().u32(webm_ab.byteLength).data.concat([webm_ab])
            ),
        {mime:"application/ncp"}
    );
    return ncp_blob;
}

btnSend.el.addEventListener("click",async ()=>{
    var nblob = await makeNcpBlob(recordedBlobs);
    Import({url:"/send",method:"POST",type:Import.Binary,data : nblob })
    .done((data)=>{
        console.log(data);
        var json = JSON.parse(data);
        if(!json.result) {
            alert("can't save this record, interrupted on server.");
            return;
        }
        refresh_list(true);
    })
    .send();
});


self.app.events.on("updateTracks",async ()=>{
    // do not remove duplicate tracks cause it may be same track name for different folders
    console.log("update tracks");
    tracksView.$.elementsClear();
    
    async function addTrack(n,track) {
        if(track.type == "audio") {
            var schema = await tracksView.$.elementPushPacketAsync(`
                <div style="display:flex;">
                    <div style="padding-left:5px;padding-right:5px;">üîä ${(""+n).padStart(2,"0")}</div>
                    <div style="padding-left:5px;padding-right:5px;width:100px;overflow:hidden;white-space: nowrap;">${track.data.name}</div>
                    <div style="padding-left:5px;padding-right:5px;"><button id="btnHit">hit</button></div>
                </div>
            `);
            schema.el.btnHit.addEventListener("click",()=>{
                self.app.events.emit("hitTrack",[n]);
            });
        } else if(track.type == "video") {
            var schema = await tracksView.$.elementPushPacketAsync(`
                <div style="display:flex;">
                    <div style="padding-left:5px;padding-right:5px;">üîä ${(""+n).padStart(2,"0")}</div>
                    <div style="padding-left:5px;padding-right:5px;width:100px;overflow:hidden;white-space: nowrap;">${track.data.name}</div>
                    <div style="padding-left:5px;padding-right:5px;"><button id="btnHit">MS</button></div>
                    <div style="padding-left:5px;padding-right:5px;"><button id="btnPip">PIP</button></div>
                </div>
            `);
            schema.el.btnHit.addEventListener("click",()=>{
                self.app.events.emit("msTrack",[n]);
            });
            schema.el.btnPip.addEventListener("click",()=>{
                self.app.events.emit("pipTrack",[n]);
            });

        } else if(track.type == "image") {
            var schema = await tracksView.$.elementPushPacketAsync(`
                <div style="display:flex;">
                    <div style="padding-left:5px;padding-right:5px;">üîä ${(""+n).padStart(2,"0")}</div>
                    <div style="padding-left:5px;padding-right:5px;width:100px;overflow:hidden;white-space: nowrap;">${track.data.name}</div>
                    <div style="padding-left:5px;padding-right:5px;"><button id="btnHit">MS</button></div>
                </div>
            `);
            schema.el.btnHit.addEventListener("click",()=>{
                self.app.events.emit("msTrack",[n]);
            });

        }
    }

    if(self.app.tracks.length>0) lblTracks.el.style.display = "";
    else lblTracks.el.style.display = "none";
    for(var x =0; x < self.app.tracks.length;x++) {
        addTrack(x,self.app.tracks[x]);
    }

    if(self.app.hasVideoTracks()) {
        recordHolder.el.style.display = "";
        var schema = await camera_holder.$.elementSetPacketAsync(`
            <div id="mockWidth"></div>
            <canvas id="videoOutput" style="border:solid 1px #000;background-color:#000;"></canvas>
        `);
        var videoOutputSize = [parseInt(screenWidth.el.value),parseInt(screenHeight.el.value)];
        schema.el.videoOutput.setAttribute("width",videoOutputSize[0]);
        schema.el.videoOutput.setAttribute("height",videoOutputSize[1]);
        if(videoOutputSize[0] < schema.el.mockWidth.offsetWidth) {
            schema.el.videoOutput.style.width = videoOutputSize[0] + 'px';
        } else {
            schema.el.videoOutput.style.width = "100%";
        }
        //schema.el.videoOutput.style.display = "none";
        // unique template
        var ctx = schema.el.videoOutput.getContext("2d");
        self.app.video.canvasFlag = true;
        var lastTrack = -1;
        var lastPipTrack = -1;
        var backstream = {
            id : null,
            stream : null
        };

        self.app.video.output = async function() {
            if(!self.app.video.canvasFlag) return;
            if("msTrack" in self.app.video) {
                var track = self.app.tracks[self.app.video.msTrack];
                if(lastTrack!=self.app.video.msTrack) {
                    if(track.type == "video") {
                        if(track.data.type == "clip") {
                            // loop
                            console.log("clip");
                            track.data.el.currentTime= 0;
                            track.data.el.play();     
                            var f = ()=>{
                                lastTrack = -1;
                                track.data.el.removeEventListener("ended",self.app.video.clip.handler);
                            };
                            self.app.video.clip = {
                                handler : f
                            };
                            track.data.el.addEventListener("ended",f);
                        } else if(track.data.type == "image") {
                            // maybe switching stream to the original may do it faster than printing every frame.
                            ctx.drawImage(track.data.el, 0, 0, track.data.el.width, track.data.el.height, 0, 0, videoOutputSize[0], videoOutputSize[1]);
                            
                         } else if(track.data.type == "screen") {
                         } else if(track.data.type == "camera") {
                         }
                    }
                    lastTrack = self.app.video.msTrack;
                }
                if(track.type == "video") { // camera, screen, video asset
                    if(track.data.type == "image") {
                        //ctx.drawImage(track.data.el, 0, 0, track.data.el.width, track.data.el.height, 0, 0, 1920, 1080);
                    } else {
                        ctx.drawImage(track.data.el, 0, 0, track.data.el.videoWidth, track.data.el.videoHeight, 0, 0, videoOutputSize[0], videoOutputSize[1]);
                    }
                }
            }
            if("pipTrack" in self.app.video && self.app.video.pipTrack!=-1) {
                var nsz = [videoOutputSize[0]/4, videoOutputSize[1]/4];
                var track = self.app.tracks[self.app.video.pipTrack];
                if(lastTrack!=self.app.video.msTrack) {
                    if(track.type == "video") {
                        if(track.data.type == "clip") {
                            console.log("clip");
                            track.data.el.currentTime= 0;
                            track.data.el.play();     
                            var f = ()=>{
                                lastTrack = -1;
                                track.data.el.removeEventListener("ended",self.app.video.clip.handler);
                            };
                            self.app.video.clip = {
                                handler : f
                            };
                            track.data.el.addEventListener("ended",f);
                        } else if(track.data.type == "image") {
                            ctx.drawImage(track.data.el, 0, 0, track.data.el.width, track.data.el.height, 3*nsz[0] - 0.1*nsz[0], 3*nsz[1] - 0.1*nsz[0], nsz[0], nsz[1]);
                        }
                    }
                }
                if(track.type == "video") {
                    if(track.data.type == "image") {

                    } else {
                        
                        ctx.drawImage(track.data.el, 0, 0, track.data.el.videoWidth, track.data.el.videoHeight, 3*nsz[0] - 0.1*nsz[0],3*nsz[1]-0.1*nsz[0], nsz[0], nsz[1]);
                    }
                }
                lastPipTrack = self.app.video.pipTrack;
            }
            setTimeout(()=>{
                self.app.video.output();
            },10);
        };
        self.app.video.output();
        self.app.stream = stream = schema.el.videoOutput.captureStream(60);
        stream.getTracks().forEach((track)=>{
            if( track.kind == "video" ) {
                backstream.id = track.id;
                backstream.stream = stream;
            }
        });
        self.app.video.mode = "play";

    } else {
        self.app.video.canvasFlag = false;
    }
});
self.app.events.on("msTrack",(n)=>{
    self.app.video.msTrack = n;
    if(self.app.recordState == "stopped") {
        recordHolder.el.style.display = "";
    }
});
self.app.events.on("pipTrack",(n)=>{
    if(self.app.video.pipTrack == n) {
        self.app.video.pipTrack = -1;
    } else {
        self.app.video.pipTrack = n;
    }
    if(self.app.recordState == "stopped") {
        recordHolder.el.style.display = "";
    }
});

async function addAsset(item) {
    var visible = false;
    var itemStruct = {
        init : false,
        data : item
    };
    var schema1 = await schema.$.list.elementUnshiftPacketAsync(`
        <tr style="cursor:pointer;">
            <td id="item">üìº ${item.id}</td>
            <td>üîΩ<a href="/messages/user1/${item.file}.ncp" download>download</a></td>
            <td id="addAsTrack">üìå add as track</td>
        </tr>
        <Component id="holder"></Component>
    `);
    itemStruct.schema1 = schema1;
    schema1.el.item.addEventListener("click",async ()=>{
        if(!visible) {
            if(!itemStruct.init) {
                itemStruct.init = true;
                var url = `/messages/user1/${item.file}.ncp`;

                var data = await fetch(url);
                var blob = await data.blob();
                var schema2 = await schema1.$.holder.elementPushPacketAsync(`
                    <tr id="view">
                        <td colspan="3" align="center">
                            <div>üìÖ ${item.date}</div>
                            <Component id="ncp" src="ncp.super" data={{this.src}}></Component>
                            <div id="sc"></div>
                        </td>
                    </tr>
                `,{context:{src:blob}});
                itemStruct.schema2 = schema2;
                schema2.el.sc.scrollIntoView({block:"center"});S
                schema2.exports.ncp.control.el.play();
                if( schema2.exports.ncp.spec.type == "audio.webm" ) {

                } else if(schema2.exports.ncp.spec.type == "video.webm") { // video tag, expecting bad margin, 100% width is custom
                    schema2.exports.ncp.control.el.style.width = "100%";
                    schema2.exports.ncp.control.el.style.marginBottom = "-7px";
                }
            } else {
                itemStruct.schema2.el.view.style.display = "";
                itemStruct.schema2.el.sc.scrollIntoView({block:"center"});
                itemStruct.schema2.exports.ncp.control.el.play();
            }
            
            visible = true;
        } else {
            itemStruct.schema2.el.view.style.display = "none";
            visible = false;
        }
    });
    var clipNb = 0;
    schema1.el.addAsTrack.addEventListener("click",async ()=>{
        console.log("addAsTrack");
        var data = await fetch(`/messages/user1/${item.file}.ncp`);
        var blob = await data.blob();
        async function load() {

            var file_ab = await this.props.data.arrayBuffer();
            var br = new BinaryReader(this.props.data,file_ab);
            var sz = br.u32();
            var config_blob = br.toBlob(sz);
            var config_ab = await config_blob.arrayBuffer();
            var json_str = Binary.utf8ab2str(config_ab,config_ab.byteLength);
            this.spec = JSON.parse(json_str);

            // bound to 0.0.1
            if( this.spec.type == "audio.webm" ) {
                var sz2 = br.u32();
                var webm_blob = br.toBlob(sz2);
                // change by this point compared to control
                var arrayBuffer = await webm_blob.arrayBuffer();
                var audio = new AudioContext();
                var bufferSource = await audio.decodeAudioData(arrayBuffer);
                var track = {
                    type : "audio",
                    data : {
                        mime : "application/ncp",
                        name : item.file + ".ncp",
                        audio : audio,
                        buffer : bufferSource
                    },
                    events : []
                };
                self.app.tracks.push(track);
                self.app.events.emit("updateTracks");
                console.log(track);
            } else if(this.spec.type == "video.webm") {

                var sz2 = br.u32();
                var webm_blob = br.toBlob(sz2);

                var videoel = document.createElement("video");
                var url = URL.createObjectURL(webm_blob);
                videoel.src = url;
                videoel.play();
                var stream = videoel.captureStream();//videoel.srcObject = await webm_blob.stream();
                var track = {
                    type : "video",
                    data : {
                        name : "clip" + clipNb,
                        type : "clip",
                        stream : stream,
                        el : videoel
                    },
                    events : []
                }
                clipNb++;
                self.app.tracks.push(track);
                self.app.events.emit("updateTracks");
                console.log(track);
            }
            // end bound
        }
        load.apply({props:{data:blob}}); // to reuse this.zip same as ncp.super
    });
}



</script>
